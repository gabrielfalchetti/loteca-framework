name: Loteca Make Ticket (Concurso)

on:
  workflow_dispatch:
    inputs:
      rodada:
        description: 'Identificador da rodada (ex.: 2025-09-27_1213)'
        required: true
        type: string
      days_window:
        description: 'Janela ±dias (RapidAPI fixtures/odds)'
        required: false
        default: '2'
        type: string
      min_match:
        description: 'Similaridade mínima fuzzy (0-100)'
        required: false
        default: '85'
        type: string
      max_duplos:
        description: 'Máximo de duplos'
        required: false
        default: '4'
        type: string
      max_triplos:
        description: 'Máximo de triplos'
        required: false
        default: '2'
        type: string

jobs:
  make_ticket:
    runs-on: ubuntu-latest
    env:
      LOTECA_RODADA: ${{ inputs.rodada }}
      ODDS_API_KEY: ${{ secrets.ODDS_API_KEY }}
      RAPIDAPI_KEY: ${{ secrets.RAPIDAPI_KEY }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install deps (end-to-end)
        run: |
          python -m pip install --upgrade pip
          pip install pandas numpy scikit-learn joblib requests PyYAML rapidfuzz==3.9.7 matplotlib

      # 1) matches.csv
      - name: Ensure matches.csv
        shell: bash
        run: |
          set -e
          if [ -s "data/out/${LOTECA_RODADA}/matches.csv" ]; then
            echo "[ensure] matches.csv já existe."
          else
            if [ -s "data/in/${LOTECA_RODADA}/matches_source.csv" ]; then
              python scripts/ingest_matches.py --rodada "${LOTECA_RODADA}"
            else
              echo "::error::Crie data/in/${LOTECA_RODADA}/matches_source.csv (match_id,home,away[,date])."
              exit 2
            fi
          fi
          test -s "data/out/${LOTECA_RODADA}/matches.csv" || { echo "::error::matches.csv ausente"; exit 2; }

      # 2) odds.csv (coleta se faltar) + consenso
      - name: Ensure odds.csv (ingest/consensus if missing)
        shell: bash
        run: |
          set -e
          if [ -s "data/out/${LOTECA_RODADA}/odds.csv" ]; then
            echo "[ensure] odds.csv já existe."
          else
            if [ -n "${ODDS_API_KEY}" ]; then
              python scripts/ingest_odds.py \
                --rodada "${LOTECA_RODADA}" \
                --sport soccer_brazil_campeonato \
                --regions uk,eu \
                --market h2h \
                --allow-partial \
                --min-match ${{ inputs.min_match }} || true
            else
              echo "[ensure] ODDS_API_KEY não definido — pulando TheOddsAPI."
            fi

            if [ -n "${RAPIDAPI_KEY}" ]; then
              python scripts/ingest_odds_apifootball_rapidapi.py \
                --rodada "${LOTECA_RODADA}" \
                --allow-partial \
                --days-window ${{ inputs.days_window }} \
                --min-match ${{ inputs.min_match }} || true
            else
              echo "[ensure] RAPIDAPI_KEY não definido — pulando API-Football."
            fi

            python scripts/merge_odds_consensus.py --rodada "${LOTECA_RODADA}" || true
          fi
          test -s "data/out/${LOTECA_RODADA}/odds.csv" || { echo "::error::odds.csv ausente após tentativa de coleta/merge"; exit 2; }

      # 3) modelagem (xG + DC + stacking)
      - name: Build probabilities (xG + Dixon-Coles + stacking)
        run: |
          python scripts/features_xg.py --rodada "${LOTECA_RODADA}"
          python scripts/features_xg_bivar.py --rodada "${LOTECA_RODADA}" --kmax 10
          if [ -s "data/history/calibration.csv" ]; then
            python scripts/calib_isotonic.py --history-path "data/history/calibration.csv" --out-path "models/calib_isotonic.pkl"
          else
            echo "[calib] histórico ausente; seguindo sem isotônica."
          fi
          python scripts/stack_probs_bivar.py --rodada "${LOTECA_RODADA}" --w-consensus 0.5 --w-xg 0.2 --w-bivar 0.2 --w-ml 0.1 --calib-path "models/calib_isotonic.pkl" || true
          # fallback: se o bivariado não existir, usa stacking univariado
          if [ ! -s "data/out/${LOTECA_RODADA}/joined_stacked_bivar.csv" ]; then
            python scripts/stack_probs.py --rodada "${LOTECA_RODADA}" --w-consensus 0.6 --w-xg 0.4 --calib-path "models/calib_isotonic.pkl" || true
          fi

      # 4) gerar cartão com até 4 duplos e 2 triplos
      - name: Make Loteca ticket (max 4 duplos, 2 triplos)
        shell: bash
        run: |
          set -e
          python - <<'PY'
          import os, pandas as pd, numpy as np, math, json
          from pathlib import Path

          rodada = os.environ["LOTECA_RODADA"]
          base = Path(f"data/out/{rodada}")
          base.mkdir(parents=True, exist_ok=True)

          # 1) carrega probs finais (prioridade bivariado > stacking > consenso)
          def load_probs():
              tried = [
                  ("joined_stacked_bivar.csv", ["p_home_final","p_draw_final","p_away_final"]),
                  ("joined_stacked.csv",       ["p_home_final","p_draw_final","p_away_final"]),
                  ("joined.csv",               ["p_home","p_draw","p_away"])
              ]
              for fn, cols in tried:
                  fp = base/fn
                  if fp.exists() and fp.stat().st_size>0:
                      df = pd.read_csv(fp).rename(columns=str.lower)
                      have = [c for c in cols if c in df.columns]
                      if len(have)==3:
                          P = df[have].to_numpy(float, copy=True)
                          P = np.clip(P,1e-12,1.0); P = P/P.sum(axis=1,keepdims=True)
                          return df, P
              raise SystemExit("::error::Nenhum arquivo de probabilidades encontrado.")

          dfp, P = load_probs()
          # 2) casa nomes home/away
          matches = pd.read_csv(base/"matches.csv").rename(columns=str.lower)
          if {"home","away"}.issubset(dfp.columns):
              df = dfp.merge(matches[["match_id","home","away"]], on="match_id", how="left", suffixes=("","_m"))
              df["home"] = df["home"].fillna(df["home_m"])
              df["away"] = df["away"].fillna(df["away_m"])
          else:
              df = dfp.merge(matches[["match_id","home","away"]], on="match_id", how="left")

          # 3) constrói cartão com até max_duplos e max_triplos (jogos mais incertos)
          max_duplos   = int(os.getenv("INPUT_MAX_DUPLOS","4"))
          max_triplos  = int(os.getenv("INPUT_MAX_TRIPLOS","2"))
          n = P.shape[0]
          def entropy_row(p): 
              p = np.clip(p,1e-12,1.0); p = p/p.sum()
              return float(-(p*np.log(p)).sum())
          ent = np.array([entropy_row(P[i]) for i in range(n)])
          order = np.argsort(ent)[::-1]  # mais incertos primeiro

          # start: secos no argmax
          picks = [ {int(np.argmax(P[i]))} for i in range(n) ]
          used_d = used_t = 0
          for idx in order:
              if used_t < max_triplos:
                  picks[idx] = {0,1,2}
                  used_t += 1
              elif used_d < max_duplos:
                  top2 = np.argsort(P[idx])[::-1][:2]
                  picks[idx] = {int(top2[0]), int(top2[1])}
                  used_d += 1

          # 4) exporta para .csv e .txt em formato Loteca
          map_sym = {0:"1", 1:"X", 2:"2"}
          rows=[]
          for i, r in df.sort_values("match_id").iterrows():
              choices = "".join(sorted(map_sym[x] for x in sorted(list(picks[int(r['match_id'])-1]))))
              rows.append({
                  "match_id": int(r["match_id"]),
                  "home": r["home"],
                  "away": r["away"],
                  "pick": choices
              })

          out_csv = base/"loteca_ticket.csv"
          pd.DataFrame(rows).to_csv(out_csv, index=False)

          # custo aproximado em nº de combinações (sem valor R$ específico)
          combos = 1
          cnt_d = cnt_t = 0
          for r in rows:
              m = len(r["pick"])
              combos *= m
              if m==2: cnt_d += 1
              if m==3: cnt_t += 1

          out_txt = base/"loteca_ticket.txt"
          with open(out_txt, "w", encoding="utf-8") as f:
              f.write(f"Cartão Loteca — {rodada}\n")
              f.write(f"(Duplos={cnt_d}, Triplos={cnt_t}, Combinações={combos})\n\n")
              for r in rows:
                  mid = r["match_id"]
                  f.write(f"{mid:>2}  {r['home']} x {r['away']:<24} → {r['pick']}\n")

          print(f"[ticket] OK -> {out_txt}")
          PY

      - name: Show ticket
        run: |
          echo "==== loteca_ticket.txt ===="
          cat "data/out/${LOTECA_RODADA}/loteca_ticket.txt" || true

      - name: Upload artifacts (ticket)
        uses: actions/upload-artifact@v4
        with:
          name: loteca-ticket-${{ inputs.rodada }}
          path: |
            data/out/${{ inputs.rodada }}/loteca_ticket.txt
            data/out/${{ inputs.rodada }}/loteca_ticket.csv
            data/out/${{ inputs.rodada }}/joined_stacked_bivar.csv
            data/out/${{ inputs.rodada }}/odds.csv
            data/out/${{ inputs.rodada }}/matches.csv
