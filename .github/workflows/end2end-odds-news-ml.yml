---
name: End2End Odds + News + ML (Strict)

on:
  workflow_dispatch:
  push:
    branches:
      - main
    paths:
      - ".github/workflows/end2end-odds-news-ml.yml"
      - "scripts/**"
      - "data/in/**"
      - "requirements.txt"

env:
  PYTHONUTF8: "1"
  PIP_DISABLE_PIP_VERSION_CHECK: "1"
  PIP_NO_WARN_SCRIPT_LOCATION: "1"

jobs:
  lint-yaml:
    name: Lint workflows (yamllint + actionlint)
    runs-on: ubuntu-24.04
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install yamllint
        run: |
          sudo apt-get update -qq
          sudo apt-get install -y yamllint

      - name: Install actionlint
        run: |
          set -euo pipefail
          curl -sSL \
            https://raw.githubusercontent.com/rhysd/actionlint/main/scripts/download-actionlint.bash \
            | bash -s -- -d ./bin
          echo "${GITHUB_WORKSPACE}/bin" >> $GITHUB_PATH

      - name: Run yamllint
        run: |
          echo "Validating YAML..."
          yamllint .github/workflows/*.yml || true

      - name: Run actionlint (all workflows)
        run: |
          set -euo pipefail
          actionlint -color -verbose

  end2end:
    name: Odds + ML + Ticket (Strict)
    runs-on: ubuntu-24.04
    needs: lint-yaml
    env:
      SEASON: "2025"
      REGIONS: "uk,eu,us,au"
      LOOKAHEAD_DAYS: "3"
      BANKROLL: "1000"
      KELLY_FRACTION: "0.5"
      KELLY_CAP: "0.1"
      KELLY_TOP_N: "14"
      ROUND_TO: "1"
      DEBUG_FLAG: "--debug"
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install Python deps
        run: |
          set -euo pipefail
          python -m pip install -U pip wheel
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          fi
          # Garantir deps usadas nos scripts/validações
          pip install \
            pandas numpy scipy scikit-learn pyyaml unidecode requests

      - name: Prepare run folders and inputs
        id: prep
        shell: bash
        run: |
          set -euo pipefail
          RUN_ID="$(date +%s)"
          echo "RUN_ID=${RUN_ID}" | tee -a "$GITHUB_OUTPUT"
          echo "OUT_DIR=data/out/${RUN_ID}" | tee -a "$GITHUB_ENV"
          echo "RUN_ID=${RUN_ID}"
          echo "OUT_DIR=${OUT_DIR:-data/out/${RUN_ID}}"
          mkdir -p "data/in" "${OUT_DIR}"

          # Garante aliases.json
          if [ ! -s "data/in/aliases.json" ]; then
            echo '{"teams": {}}' > data/in/aliases.json
          fi

          # Garante matches_source.csv
          if [ ! -s "data/in/matches_source.csv" ]; then
            echo "::error::Arquivo obrigatório ausente: data/in/matches_source.csv"
            exit 2
          fi

      - name: Normalize matches_source -> matches_whitelist.csv
        shell: bash
        run: |
          set -euo pipefail
          SRC="data/in/matches_source.csv"
          DST_RAW="${OUT_DIR}/matches_whitelist_raw.csv"
          DST_NORM="${OUT_DIR}/matches_whitelist.csv"

          tr -d '\r' < "$SRC" \
            | sed -E 's/[[:space:]]+/ /g; s/ *, */,/g; s/^ //; s/ $//' > "$DST_RAW"

          header="$(head -n1 "$DST_RAW")"
          h_low="$(echo "$header" | tr '[:upper:]' '[:lower:]')"
          for need in match_id home away; do
            echo "$h_low" \
              | grep -qiE "(^|,)$need(,|$)" \
              || { echo "::error::missing column '$need' in matches_source.csv"; exit 2; }
          done

          awk -F',' -v OFS=',' '
            function rmuf(s){ gsub(/\/[A-Za-z]{2}($|[^A-Za-z])/, "", s); return s }
            function deacc(s){
              gsub(/á|à|ã|â|ä/,"a",s); gsub(/Á|À|Ã|Â|Ä/,"A",s);
              gsub(/é|ê|è|ë/,"e",s);  gsub(/É|Ê|È|Ë/,"E",s);
              gsub(/í|î|ì|ï/,"i",s);  gsub(/Í|Î|Ì|Ï/,"I",s);
              gsub(/ó|ô|ò|õ|ö/,"o",s); gsub(/Ó|Ô|Ò|Õ|Ö/,"O",s);
              gsub(/ú|û|ù|ü/,"u",s);  gsub(/Ú|Û|Ù|Ü/,"U",s);
              gsub(/ç/,"c",s);        gsub(/Ç/,"C",s);
              gsub(/ñ/,"n",s);        gsub(/Ñ/,"N",s);
              return s
            }
            function trim(s){ sub(/^ +/,"",s); sub(/ +$/,"",s); return s }
            function map_pt_en(s,  l){
              l=tolower(s)
              if(l=="estonia") return "Estonia"
              if(l=="italia") return "Italy"
              if(l=="bulgaria") return "Bulgaria"
              if(l=="turquia") return "Turkey"
              if(l=="espanha") return "Spain"
              if(l=="georgia") return "Georgia"
              if(l=="servia" || l=="serbia/ser" || l=="serbia") return "Serbia"
              if(l=="albania") return "Albania"
              if(l=="portugal") return "Portugal"
              if(l=="irlanda") return "Ireland"
              if(l=="holanda" || l=="paises baixos") return "Netherlands"
              if(l=="finlandia") return "Finland"
              if(l=="romenia") return "Romania"
              if(l=="austria") return "Austria"
              if(l=="dinamarca") return "Denmark"
              if(l=="grecia") return "Greece"
              if(l=="lituania") return "Lithuania"
              if(l=="polonia") return "Poland"
              if(l=="ponte preta") return "Ponte Preta"
              if(l=="guarani") return "Guarani"
              if(l=="palmeiras") return "Palmeiras"
              if(l=="juventude") return "Juventude"
              if(l=="criciuma") return "Criciuma"
              if(l=="america/mg" || l=="america mg" || l=="america-mg" || l=="america mineiro") return "America Mineiro"
              if(l=="cuiaba") return "Cuiaba"
              if(l=="coritiba") return "Coritiba"
              if(l=="novorizontino" || l=="gremio novorizontino" || l=="grêmio novorizontino") return "Gremio Novorizontino"
              if(l=="operario" || l=="operario pr" || l=="operario/pr" || l=="operário/pr") return "Operario PR"
              return s
            }
            NR==1{
              for(i=1;i<=NF;i++){
                k=tolower($i);
                if(k=="match_id") mi=i;
                if(k=="home") hi=i;
                if(k=="away") ai=i;
              }
              if(!(mi&&hi&&ai)){ print "::error::header mapping failed"; exit 2 }
              print "match_id","home","away";
              next
            }
            {
              mid=$mi; home=$hi; away=$ai;
              home=rmuf(home); away=rmuf(away);
              home=deacc(home); away=deacc(away);
              home=trim(home); away=trim(away);
              home=map_pt_en(home); away=map_pt_en(away);
              if(mid=="" || home=="" || away==""){ print "::error::empty field on line " NR; exit 2 }
              if(seen[mid]++){ print "::error::duplicate match_id: " mid; exit 2 }
              print mid,home,away
            }
          ' "$DST_RAW" > "$DST_NORM"

          LINES=$(wc -l < "$DST_NORM" | tr -d " ")
          [ "$LINES" -ge 2 ] || {
            echo "::error::whitelist empty after normalization"
            exit 3
          }

          echo "===== Preview normalized whitelist ====="
          head -n 30 "$DST_NORM" || true

      - name: Validate normalized team names (strict)
        shell: python
        run: |
          import csv, sys, os, json, re
          out_dir = os.environ.get("OUT_DIR")
          if not out_dir:
            print("::error::OUT_DIR not set")
            sys.exit(2)
          wl = os.path.join(out_dir, "matches_whitelist.csv")
          ali = "data/in/aliases.json"
          if not os.path.exists(wl):
            print("::error::whitelist not found")
            sys.exit(2)
          if not os.path.exists(ali):
            print("::error::aliases.json not found")
            sys.exit(2)
          with open(ali, "r", encoding="utf-8") as f:
            aliases = json.load(f).get("teams", {})
          bad = []
          with open(wl, newline="", encoding="utf-8") as f:
            rd = csv.DictReader(f)
            for i, row in enumerate(rd, start=2):
              h = row["home"].strip()
              a = row["away"].strip()
              # Regras simples: sem barras, sem números, fallback por aliases
              for name in (h, a):
                if "/" in name or re.search(r"\d", name):
                  bad.append((i, name, "invalid chars"))
              # Alerta se não há alias conhecido (não bloqueia)
              for k in (h, a):
                if k not in aliases:
                  print(f"::warning::alias ausente para '{k}'")
          if bad:
            for i, nm, why in bad:
              print(f"::error::linha {i} nome '{nm}' inválido: {why}")
            sys.exit(2)

      - name: Ingest odds – API-Football (mandatory)
        shell: bash
        env:
          X_RAPIDAPI_KEY: ${{ secrets.X_RAPIDAPI_KEY }}
        run: |
          set -euo pipefail
          [ -f scripts/ingest_odds_apifootball_rapidapi.py ] \
            || { echo "::error::scripts/ingest_odds_apifootball_rapidapi.py not found"; exit 5; }
          a=0
          until [ $a -ge 3 ]; do
            python -m scripts.ingest_odds_apifootball_rapidapi \
              --rodada "${OUT_DIR}" \
              --season "${SEASON}" \
              ${DEBUG_FLAG} && break
            a=$((a+1)); echo "retry apifootball: $a/3"; sleep $((5*a))
          done
          OUT="${OUT_DIR}/odds_apifootball.csv"
          test -s "$OUT" || { echo "::error::odds_apifootball.csv not generated"; exit 5; }
          header="$(head -n1 "$OUT" | tr -d '\r')"
          for c in match_id home away odds_home odds_draw odds_away; do
            echo "$header" | grep -qiE "(^|,)$c(,|$)" \
              || { echo "::error::missing column '$c' in odds_apifootball.csv"; exit 5; }
          done

      - name: Ingest odds – TheOddsAPI (mandatory)
        shell: bash
        env:
          THEODDS_API_KEY: ${{ secrets.THEODDS_API_KEY }}
        run: |
          set -euo pipefail
          if [ ! -f scripts/ingest_odds_theoddsapi.py ]; then
            echo "::error::scripts/ingest_odds_theoddsapi.py not found"
            exit 5
          fi
          a=0
          until [ $a -ge 3 ]; do
            python -m scripts.ingest_odds_theoddsapi \
              --rodada "${OUT_DIR}" \
              --regions "${REGIONS}" \
              --aliases "data/in/aliases.json" \
              ${DEBUG_FLAG} && break
            a=$((a+1)); echo "retry theodds: $a/3"; sleep $((5*a))
          done
          OUT="${OUT_DIR}/odds_theoddsapi.csv"
          test -s "$OUT" || { echo "::error::odds_theoddsapi.csv not generated"; exit 5; }
          header="$(head -n1 "$OUT" | tr -d '\r')"
          for c in match_id home away odds_home odds_draw odds_away; do
            echo "$header" | grep -qiE "(^|,)$c(,|$)" \
              || { echo "::error::missing column '$c' in odds_theoddsapi.csv"; exit 5; }
          done

      - name: Consensus odds (STRICT)
        shell: bash
        run: |
          set -euo pipefail
          [ -f scripts/consensus_odds_safe.py ] \
            || { echo "::error::scripts/consensus_odds_safe.py not found"; exit 6; }
          python -m scripts.consensus_odds_safe --rodada "${OUT_DIR}" --strict
          OUT_FILE="${OUT_DIR}/odds_consensus.csv"
          test -s "$OUT_FILE" || { echo "::error::odds_consensus.csv not generated"; exit 6; }
          header="$(head -n1 "$OUT_FILE" | tr -d '\r')"
          for c in team_home team_away odds_home odds_draw odds_away; do
            echo "$header" | grep -qiE "(^|,)$c(,|$)" \
              || { echo "::error::missing column '$c' in odds_consensus.csv"; exit 6; }
          done
          head -n 20 "$OUT_FILE" || true

      - name: XG – Features univariadas
        shell: bash
        run: |
          set -euo pipefail
          [ -f scripts/xg_univar.py ] \
            || { echo "::error::scripts/xg_univar.py not found"; exit 7; }
          python -m scripts.xg_univar --rodada "${OUT_DIR}" ${DEBUG_FLAG}
          test -s "${OUT_DIR}/xg_univar.csv" \
            || { echo "::error::xg_univar.csv not generated"; exit 7; }

      - name: XG – Features bivariadas
        shell: bash
        run: |
          set -euo pipefail
          [ -f scripts/xg_bivar.py ] \
            || { echo "::error::scripts/xg_bivar.py not found"; exit 7; }
          python -m scripts.xg_bivar --rodada "${OUT_DIR}" ${DEBUG_FLAG}
          test -s "${OUT_DIR}/xg_bivar.csv" \
            || { echo "::error::xg_bivar.csv not generated"; exit 7; }

      - name: Kelly staking
        shell: bash
        env:
          BANKROLL: ${{ env.BANKROLL }}
          KELLY_FRACTION: ${{ env.KELLY_FRACTION }}
          KELLY_CAP: ${{ env.KELLY_CAP }}
          KELLY_TOP_N: ${{ env.KELLY_TOP_N }}
          ROUND_TO: ${{ env.ROUND_TO }}
        run: |
          set -euo pipefail
          [ -f scripts/kelly.py ] || { echo "::error::scripts/kelly.py not found"; exit 8; }
          python -m scripts.kelly \
            --rodada "${OUT_DIR}" \
            --bankroll "${BANKROLL}" \
            --fraction "${KELLY_FRACTION}" \
            --cap "${KELLY_CAP}" \
            --topn "${KELLY_TOP_N}" \
            --round_to "${ROUND_TO}" \
            ${DEBUG_FLAG}
          test -s "${OUT_DIR}/kelly_allocations.csv" \
            || { echo "::error::kelly_allocations.csv not generated"; exit 8; }

      - name: Montar cartão da Loteca
        shell: bash
        run: |
          set -euo pipefail
          [ -f scripts/make_ticket.py ] \
            || { echo "::error::scripts/make_ticket.py not found"; exit 9; }
          python -m scripts.make_ticket --rodada "${OUT_DIR}" ${DEBUG_FLAG}
          test -s "${OUT_DIR}/loteca_ticket.txt" \
            || { echo "::error::loteca_ticket.txt not generated"; exit 9; }
          echo "===== Prévia do cartão ====="
          cat "${OUT_DIR}/loteca_ticket.txt" | sed -n '1,120p'

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: loteca-${{ env.SEASON }}-${{ steps.prep.outputs.RUN_ID }}
          path: |
            ${{ env.OUT_DIR }}/matches_whitelist*.csv
            ${{ env.OUT_DIR }}/odds_*.csv
            ${{ env.OUT_DIR }}/xg_*.csv
            ${{ env.OUT_DIR }}/kelly_allocations.csv
            ${{ env.OUT_DIR }}/loteca_ticket.txt
          if-no-files-found: error