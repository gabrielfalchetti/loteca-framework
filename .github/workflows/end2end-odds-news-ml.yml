# .github/workflows/end2end-odds-news-ml.yml
# yamllint disable rule:line-length
---
name: end2end-odds-news-ml

on:
  push:
    paths:
      - ".github/workflows/end2end-odds-news-ml.yml"
      - "scripts/**"
      - "data/in/**"
      - "requirements*.txt"
  workflow_dispatch: {}

permissions:
  contents: read

env:
  PYTHONUTF8: "1"
  PIP_DISABLE_PIP_VERSION_CHECK: "1"
  PIP_NO_WARN_SCRIPT_LOCATION: "1"
  SEASON: "2025"
  REGIONS: "uk,eu,us,au"
  LOOKAHEAD_DAYS: "3"
  BANKROLL: "1000"
  KELLY_FRACTION: "0.5"
  KELLY_CAP: "0.1"
  KELLY_TOP_N: "14"
  ROUND_TO: "1"

jobs:
  e2e:
    runs-on: ubuntu-latest
    timeout-minutes: 60

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      # ---------- Lint do próprio workflow ----------
      - name: Lint this workflow file
        shell: bash
        run: |
          set -e
          sudo apt-get update -qq
          sudo apt-get install -y yamllint
          echo "Validating YAML..."
          yamllint .github/workflows/end2end-odds-news-ml.yml || true

      # ---------- Python ----------
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"
          cache-dependency-path: |
            requirements.txt
            requirements-dev.txt

      - name: Install deps
        shell: bash
        run: |
          set -euo pipefail
          python -V
          pip install --upgrade pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          fi
          # Extras necessários pelas etapas (corrige o ModuleNotFoundError: unidecode)
          pip install unidecode pandas numpy scipy scikit-learn requests pytz

      # ---------- OUT_DIR (fix OUT_DIR unbound) ----------
      - name: Compute run id and OUT_DIR
        id: prep
        shell: bash
        run: |
          set -euo pipefail
          RUN_ID="$(date +%s)"
          OUT_DIR="data/out/${RUN_ID}"
          export OUT_DIR
          echo "RUN_ID=${RUN_ID}" >> "$GITHUB_OUTPUT"
          echo "OUT_DIR=${OUT_DIR}" >> "$GITHUB_ENV"
          echo "RUN_ID=${RUN_ID}"
          echo "OUT_DIR=${OUT_DIR}"

      # ---------- Pastas / insumos ----------
      - name: Prepare folders and inputs
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p "data/in" "${OUT_DIR}"
          if [ ! -s "data/in/aliases.json" ]; then
            echo '{"teams": {}}' > data/in/aliases.json
          fi
          if [ ! -s "data/in/matches_source.csv" ]; then
            echo "::error::Arquivo obrigatório ausente: data/in/matches_source.csv"
            exit 2
          fi

      # ---------- Normalização de whitelist ----------
      - name: Normalize whitelist from source
        shell: bash
        run: |
          set -euo pipefail
          SRC="data/in/matches_source.csv"
          DST_RAW="${OUT_DIR}/matches_whitelist_raw.csv"
          DST_NORM="${OUT_DIR}/matches_whitelist.csv"

          tr -d '\r' < "$SRC" | sed -E 's/[[:space:]]+/ /g; s/ *, */,/g; s/^ //; s/ $//' > "$DST_RAW"

          header="$(head -n1 "$DST_RAW")"
          h_low="$(echo "$header" | tr '[:upper:]' '[:lower:]')"
          for need in match_id home away; do
            echo "$h_low" | grep -qiE "(^|,)$need(,|$)" || { echo "::error::missing column '$need' in matches_source.csv"; exit 2; }
          done

          awk -F',' -v OFS=',' '
            function rmuf(s){ gsub(/\/[A-Za-z]{2}($|[^A-Za-z])/, "", s); return s }
            function deacc(s){
              gsub(/á|à|ã|â|ä/,"a",s); gsub(/Á|À|Ã|Â|Ä/,"A",s);
              gsub(/é|ê|è|ë/,"e",s);  gsub(/É|Ê|È|Ë/,"E",s);
              gsub(/í|î|ì|ï/,"i",s);  gsub(/Í|Î|Ì|Ï/,"I",s);
              gsub(/ó|ô|ò|õ|ö/,"o",s); gsub(/Ó|Ô|Ò|Õ|Ö/,"O",s);
              gsub(/ú|û|ù|ü/,"u",s);  gsub(/Ú|Û|Ù|Ü/,"U",s);
              gsub(/ç/,"c",s);        gsub(/Ç/,"C",s);
              gsub(/ñ/,"n",s);        gsub(/Ñ/,"N",s);
              return s
            }
            function trim(s){ sub(/^ +/,"",s); sub(/ +$/,"",s); return s }
            function map_pt_en(s,  l){
              l=tolower(s)
              if(l=="estonia") return "Estonia"
              if(l=="italia") return "Italy"
              if(l=="bulgaria") return "Bulgaria"
              if(l=="turquia") return "Turkey"
              if(l=="espanha") return "Spain"
              if(l=="georgia") return "Georgia"
              if(l=="servia"||l=="serbia/ser"||l=="serbia") return "Serbia"
              if(l=="albania") return "Albania"
              if(l=="portugal") return "Portugal"
              if(l=="irlanda") return "Ireland"
              if(l=="holanda"||l=="paises baixos") return "Netherlands"
              if(l=="finlandia") return "Finland"
              if(l=="romenia") return "Romania"
              if(l=="austria") return "Austria"
              if(l=="dinamarca") return "Denmark"
              if(l=="grecia") return "Greece"
              if(l=="lituania") return "Lithuania"
              if(l=="polonia") return "Poland"
              if(l=="ponte preta") return "Ponte Preta"
              if(l=="guarani") return "Guarani"
              if(l=="palmeiras") return "Palmeiras"
              if(l=="juventude") return "Juventude"
              if(l=="criciuma") return "Criciuma"
              if(l=="america/mg"||l=="america mg"||l=="america-mg"||l=="america mineiro") return "America Mineiro"
              if(l=="cuiaba") return "Cuiaba"
              if(l=="coritiba") return "Coritiba"
              if(l=="novorizontino"||l=="gremio novorizontino"||l=="grêmio novorizontino") return "Gremio Novorizontino"
              if(l=="operario"||l=="operario pr"||l=="operario/pr"||l=="operário/pr") return "Operario PR"
              return s
            }
            NR==1{
              for(i=1;i<=NF;i++){
                k=tolower($i);
                if(k=="match_id") mi=i;
                if(k=="home") hi=i;
                if(k=="away") ai=i;
              }
              if(!(mi&&hi&&ai)){ print "::error::header mapping failed"; exit 2 }
              print "match_id","home","away"; next
            }
            {
              mid=$mi; home=$hi; away=$ai;
              home=rmuf(home); away=rmuf(away);
              home=deacc(home); away=deacc(away);
              home=trim(home);  away=trim(away);
              home=map_pt_en(home); away=map_pt_en(away);
              if(mid=="" || home=="" || away==""){
                print "::error::empty field on line " NR; exit 2
              }
              if(seen[mid]++){ print "::error::duplicate match_id: " mid; exit 2 }
              print mid,home,away
            }
          ' "$DST_RAW" > "$DST_NORM"

          LINES=$(wc -l < "$DST_NORM" | tr -d " ")
          [ "$LINES" -ge 2 ] || { echo "::error::whitelist empty after normalization"; exit 3; }

          # Evita "cp: files are the same" quando destino já é o mesmo arquivo
          if [ ! -e "${OUT_DIR}/matches_whitelist.csv" ] || ! cmp -s "$DST_NORM" "${OUT_DIR}/matches_whitelist.csv"; then
            cp "$DST_NORM" "${OUT_DIR}/matches_whitelist.csv"
          fi

          echo "===== Preview normalized whitelist ====="
          head -n 30 "$DST_NORM" || true

      # ---------- Validação de nomes ----------
      - name: Validate team names before ingest
        shell: bash
        run: |
          set -euo pipefail
          WL="${OUT_DIR}/matches_whitelist.csv"
          test -s "$WL" || { echo "::error::whitelist not found"; exit 3; }
          python - <<'PY'
import csv, sys, re, os
from unidecode import unidecode
wl = os.getenv("OUT_DIR", "") + "/matches_whitelist.csv"
bad = []
with open(wl, newline='', encoding='utf-8') as f:
    rd = csv.DictReader(f)
    for i, row in enumerate(rd, start=2):
        for k in ("match_id", "home", "away"):
            if not row.get(k, "").strip():
                bad.append(f"line {i}: empty {k}")
        for side in ("home", "away"):
            v = row[side]
            if len(v) < 2 or re.search(r"[^A-Za-z0-9 .'-]", v):
                bad.append(f"line {i}: suspicious name '{v}'")
if bad:
    print("::error::Invalid names in whitelist:")
    for b in bad:
        print(b)
    sys.exit(4)
print("[validate] names ok")
PY

      # ---------- API-Football (obrigatória) ----------
      - name: Ingest odds - API-Football (mandatory)
        env:
          X_RAPIDAPI_KEY: ${{ secrets.X_RAPIDAPI_KEY }}
        shell: bash
        run: |
          set -euo pipefail
          [ -f scripts/ingest_odds_apifootball_rapidapi.py ] || { echo "::error::scripts/ingest_odds_apifootball_rapidapi.py not found"; exit 5; }
          a=0; until [ $a -ge 3 ]; do
            python -m scripts.ingest_odds_apifootball_rapidapi \
              --rodada "${OUT_DIR}" \
              --season "${SEASON}" \
              --debug && break
            a=$((a+1)); echo "retry apifootball: $a/3"; sleep $((5*a))
          done
          OUT="${OUT_DIR}/odds_apifootball.csv"
          test -s "$OUT" || { echo "::error::odds_apifootball.csv not generated"; exit 5; }
          header="$(head -n1 "$OUT" | tr -d '\r')"
          for c in match_id home away odds_home odds_draw odds_away; do
            echo "$header" | grep -qiE "(^|,)$c(,|$)" || { echo "::error::missing column '$c' in odds_apifootball.csv"; exit 5; }
          done

      # ---------- TheOddsAPI (obrigatória) ----------
      - name: Ingest odds - TheOddsAPI (mandatory)
        env:
          THEODDS_API_KEY: ${{ secrets.THEODDS_API_KEY }}
        shell: bash
        run: |
          set -euo pipefail
          [ -f scripts/ingest_odds_theoddsapi.py ] || { echo "::error::scripts/ingest_odds_theoddsapi.py not found"; exit 5; }
          a=0; until [ $a -ge 3 ]; do
            python -m scripts.ingest_odds_theoddsapi \
              --rodada "${OUT_DIR}" \
              --regions "${REGIONS}" \
              --aliases "data/in/aliases.json" \
              --debug && break
            a=$((a+1)); echo "retry theodds: $a/3"; sleep $((5*a))
          done
          OUT="${OUT_DIR}/odds_theoddsapi.csv"
          test -s "$OUT" || { echo "::error::odds_theoddsapi.csv not generated"; exit 5; }
          header="$(head -n1 "$OUT" | tr -d '\r')"
          for c in match_id home away odds_home odds_draw odds_away; do
            echo "$header" | grep -qiE "(^|,)$c(,|$)" || { echo "::error::missing column '$c' in odds_theoddsapi.csv"; exit 5; }
          done

      # ---------- Consenso (strict) ----------
      - name: Build consensus odds (strict)
        shell: bash
        run: |
          set -euo pipefail
          [ -f scripts/consensus_odds_safe.py ] || { echo "::error::scripts/consensus_odds_safe.py not found"; exit 6; }
          python -m scripts.consensus_odds_safe --rodada "${OUT_DIR}" --strict
          OUT_FILE="${OUT_DIR}/odds_consensus.csv"
          test -s "$OUT_FILE" || { echo "::error::odds_consensus.csv not generated"; exit 6; }
          header="$(head -n1 "$OUT_FILE" | tr -d '\r')"
          for c in team_home team_away odds_home odds_draw odds_away; do
            echo "$header" | grep -qiE "(^|,)$c(,|$)" || { echo "::error::missing column '$c' in odds_consensus.csv"; exit 6; }
          done
          head -n 20 "$OUT_FILE" || true

      # ---------- XG (uni & bi) ----------
      - name: "XG features (uni & bi)"
        shell: bash
        run: |
          set -euo pipefail
          [ -f scripts/features_xg.py ] || { echo "::error::scripts/features_xg.py not found"; exit 7; }
          python -m scripts.features_xg \
            --rodada "${OUT_DIR}" \
            --consensus "${OUT_DIR}/odds_consensus.csv" \
            --whitelist "${OUT_DIR}/matches_whitelist.csv" \
            --debug
          test -s "${OUT_DIR}/features_xg.csv" || { echo "::error::features_xg.csv not generated"; exit 7; }

      # ---------- Kelly ----------
      - name: Kelly sizing
        shell: bash
        run: |
          set -euo pipefail
          [ -f scripts/kelly.py ] || { echo "::error::scripts/kelly.py not found"; exit 8; }
          python -m scripts.kelly \
            --rodada "${OUT_DIR}" \
            --bankroll "${BANKROLL}" \
            --fraction "${KELLY_FRACTION}" \
            --cap "${KELLY_CAP}" \
            --top-n "${KELLY_TOP_N}" \
            --round-to "${ROUND_TO}"
          test -s "${OUT_DIR}/kelly_bets.csv" || { echo "::error::kelly_bets.csv not generated"; exit 8; }

      # ---------- Cartão da Loteca ----------
      - name: Build Loteca card
        shell: bash
        run: |
          set -euo pipefail
          [ -f scripts/build_loteca_card.py ] || { echo "::error::scripts/build_loteca_card.py not found"; exit 9; }
          python -m scripts.build_loteca_card \
            --rodada "${OUT_DIR}" \
            --whitelist "${OUT_DIR}/matches_whitelist.csv" \
            --consensus "${OUT_DIR}/odds_consensus.csv" \
            --kelly "${OUT_DIR}/kelly_bets.csv" \
            --debug
          test -s "${OUT_DIR}/loteca_card.csv" || { echo "::error::loteca_card.csv not generated"; exit 9; }
          echo "===== Preview Loteca Card ====="
          head -n 20 "${OUT_DIR}/loteca_card.csv" || true

      # ---------- Artefatos ----------
      - name: Upload outputs
        uses: actions/upload-artifact@v4
        with:
          name: loteca-${{ steps.prep.outputs.RUN_ID }}
          path: |
            ${{ env.OUT_DIR }}/matches_whitelist_raw.csv
            ${{ env.OUT_DIR }}/matches_whitelist.csv
            ${{ env.OUT_DIR }}/odds_apifootball.csv
            ${{ env.OUT_DIR }}/odds_theoddsapi.csv
            ${{ env.OUT_DIR }}/odds_consensus.csv
            ${{ env.OUT_DIR }}/features_xg.csv
            ${{ env.OUT_DIR }}/kelly_bets.csv
            ${{ env.OUT_DIR }}/loteca_card.csv
# yamllint enable