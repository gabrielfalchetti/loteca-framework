name: end2end-odds-news-ml

on:
  workflow_dispatch:
    inputs:
      debug:
        description: "Enable debug logs"
        required: false
        default: true
        type: boolean
  schedule:
    - cron: "15 09 * * 4,5"

permissions:
  contents: read

env:
  SEASON: "2025"
  REGIONS: "uk,eu,us,au"
  LOOKAHEAD_DAYS: "3"
  BANKROLL: "1000"
  KELLY_FRACTION: "0.5"
  KELLY_CAP: "0.1"
  KELLY_TOP_N: "14"
  ROUND_TO: "1"

jobs:
  run:
    runs-on: ubuntu-latest
    timeout-minutes: 60

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install deps
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          fi
          # hard deps used in the steps
          pip install pandas numpy rapidfuzz requests pytz python-dateutil

      # ---------- PREP ----------
      - name: Prepare run folders
        id: prep
        shell: bash
        run: |
          set -euo pipefail
          RUN_ID="$(date +%s)"
          echo "RUN_ID=${RUN_ID}" >> "$GITHUB_OUTPUT"
          OUT_DIR="data/out/${RUN_ID}"
          echo "OUT_DIR=${OUT_DIR}" >> "$GITHUB_ENV"
          mkdir -p "data/in" "${OUT_DIR}"
          if [ ! -s "data/in/aliases.json" ]; then
            echo '{"teams": {}}' > data/in/aliases.json
          fi
          if [ ! -s "data/in/matches_source.csv" ]; then
            echo "::error::Missing required file: data/in/matches_source.csv"
            exit 2
          fi

      - name: Set DEBUG_FLAG
        shell: bash
        run: |
          set -euo pipefail
          if [ "${{ inputs.debug }}" = "true" ]; then
            echo "DEBUG_FLAG=--debug" >> "$GITHUB_ENV"
          else
            echo "DEBUG_FLAG=" >> "$GITHUB_ENV"
          fi

      # ---------- VALIDATE WHITELIST (BASH/AWK) ----------
      - name: Validate and normalize names
        shell: bash
        run: |
          set -euo pipefail
          SRC="data/in/matches_source.csv"
          DST="${OUT_DIR}/matches_whitelist.csv"

          # Remove CR, trim spaces around commas, collapse spaces
          # and ensure the header has match_id,home,away (case-insensitive)
          TMP="${OUT_DIR}/_tmp_src.csv"
          tr -d '\r' < "$SRC" \
          | sed -E 's/[[:space:]]+/ /g; s/ *, */,/g; s/^ //; s/ $//' > "$TMP"

          header="$(head -n1 "$TMP")"
          h_low="$(echo "$header" | tr '[:upper:]' '[:lower:]')"
          for need in match_id home away; do
            echo "$h_low" | grep -qiE "(^|,)$need(,|$)" || { echo "::error::missing column '$need' in matches_source.csv"; exit 2; }
          done

          # Build whitelist (also check for duplicate match_id and empty fields)
          awk -F',' -v OFS=',' '
            NR==1{
              for(i=1;i<=NF;i++){
                k=tolower($i);
                if(k=="match_id") mi=i;
                if(k=="home") hi=i;
                if(k=="away") ai=i;
              }
              if(!(mi&&hi&&ai)){ print "::error::header mapping failed"; exit 2 }
              print "match_id","home","away";
              next
            }
            {
              mid=$mi; home=$hi; away=$ai;
              gsub(/^ +| +$/,"",mid); gsub(/^ +| +$/,"",home); gsub(/^ +| +$/,"",away);
              if(mid=="" || home=="" || away==""){ print "::error::empty field on line " NR; exit 2 }
              if(seen[mid]++){ print "::error::duplicate match_id: " mid; exit 2 }
              print mid,home,away
            }
          ' "$TMP" > "$DST"

          LINES=$(wc -l < "$DST" | tr -d ' ')
          [ "$LINES" -ge 2 ] || { echo "::error::whitelist empty"; exit 3; }

          echo "===== Preview whitelist ====="
          head -n 50 "$DST" || true

      # ---------- INGEST API-FOOTBALL (REQUIRED) ----------
      - name: Ingest odds (API-Football via RapidAPI) required
        env:
          X_RAPIDAPI_KEY: ${{ secrets.X_RAPIDAPI_KEY }}
        shell: bash
        run: |
          set -euo pipefail
          [ -f scripts/ingest_odds_apifootball_rapidapi.py ] || { echo "::error::scripts/ingest_odds_apifootball_rapidapi.py not found"; exit 5; }
          a=0; until [ $a -ge 3 ]; do
            python -m scripts.ingest_odds_apifootball_rapidapi \
              --rodada "${OUT_DIR}" \
              --season "${SEASON}" \
              ${DEBUG_FLAG} && break
            a=$((a+1)); echo "retry apifootball: $a/3"; sleep $((5*a))
          done
          OUT="${OUT_DIR}/odds_apifootball.csv"
          test -s "$OUT" || { echo "::error::odds_apifootball.csv not generated"; exit 5; }
          header="$(head -n1 "$OUT" | tr -d '\r')"
          for c in match_id home away odds_home odds_draw odds_away; do
            echo "$header" | grep -qiE "(^|,)$c(,|$)" || { echo "::error::missing column '$c' in odds_apifootball.csv"; exit 5; }
          done

      # ---------- THEODDSAPI (OPTIONAL, SOCCER ONLY) ----------
      - name: Ingest odds (TheOddsAPI) optional
        env:
          THEODDS_API_KEY: ${{ secrets.THEODDS_API_KEY }}
        shell: bash
        run: |
          set -euo pipefail
          if [ ! -f scripts/ingest_odds_theoddsapi.py ]; then
            echo "[theodds] script missing - skipping"; exit 0
          fi
          a=0; until [ $a -ge 3 ]; do
            python -m scripts.ingest_odds_theoddsapi \
              --rodada "${OUT_DIR}" \
              --regions "${REGIONS}" \
              --aliases "data/in/aliases.json" \
              ${DEBUG_FLAG} && break
            a=$((a+1)); echo "retry theodds: $a/3"; sleep $((5*a))
          done || true
          OUT="${OUT_DIR}/odds_theoddsapi.csv"
          if [ -s "$OUT" ]; then
            header="$(head -n1 "$OUT" | tr -d '\r')"
            for c in match_id home away odds_home odds_draw odds_away; do
              echo "$header" | grep -qiE "(^|,)$c(,|$)" || { echo "::warning::missing column '$c' in odds_theoddsapi.csv"; exit 0; }
            done
          else
            echo "[theodds] file not produced; proceeding with API-Football only"
          fi

      # ---------- CONSENSUS ----------
      - name: Consensus odds
        shell: bash
        run: |
          set -euo pipefail
          [ -f scripts/consensus_odds_safe.py ] || { echo "::error::scripts/consensus_odds_safe.py not found"; exit 6; }
          python -m scripts.consensus_odds_safe --rodada "${OUT_DIR}" --strict
          OUT_FILE="${OUT_DIR}/odds_consensus.csv"
          test -s "$OUT_FILE" || { echo "::error::odds_consensus.csv not generated"; exit 6; }
          header="$(head -n1 "$OUT_FILE" | tr -d '\r')"
          for c in team_home team_away odds_home odds_draw odds_away; do
            echo "$header" | grep -qiE "(^|,)$c(,|$)" || { echo "::error::missing column '$c' in odds_consensus.csv"; exit 6; }
          done
          head -n 20 "$OUT_FILE" || true

      - name: Predict from odds
        shell: bash
        run: |
          set -euo pipefail
          [ -f scripts/predict_from_odds.py ] || { echo "::error::scripts/predict_from_odds.py not found"; exit 7; }
          python scripts/predict_from_odds.py --rodada "${OUT_DIR}" ${DEBUG_FLAG}
          test -s "${OUT_DIR}/predictions_market.csv" || { echo "::error::predictions_market.csv not generated"; exit 7; }

      # ---------- FEATURES ----------
      - name: Build features univariado
        shell: bash
        run: |
          set -euo pipefail
          [ -f scripts/feature_build_univariado.py ] || { echo "::error::scripts/feature_build_univariado.py not found"; exit 21; }
          python scripts/feature_build_univariado.py --rodada "${OUT_DIR}" ${DEBUG_FLAG}
          test -s "${OUT_DIR}/features_univariado.csv" || { echo "::error::features_univariado.csv not generated"; exit 21; }

      # ---------- KELLY ----------
      - name: Publish Kelly stakes
        shell: bash
        env:
          NEWSAPI_KEY: ${{ secrets.NEWSAPI_KEY }}
          WANDB_API_KEY: ${{ secrets.WANDB_API_KEY }}
        run: |
          set -euo pipefail
          [ -f scripts/publish_kelly.py ] || { echo "::error::scripts/publish_kelly.py not found"; exit 25; }
          python scripts/publish_kelly.py --rodada "${OUT_DIR}" ${DEBUG_FLAG}
          test -s "${OUT_DIR}/kelly_stakes.csv" || { echo "::error::kelly_stakes.csv not generated"; exit 25; }

      # ---------- LOTECA CARD ----------
      - name: Build loteca card
        shell: bash
        run: |
          set -euo pipefail
          python - <<'PYCODE'
import os, sys, pandas as pd
out_dir = os.environ.get("OUT_DIR","")
p = f"{out_dir}/kelly_stakes.csv"
if not os.path.exists(p):
    print("::error::kelly_stakes.csv not found"); sys.exit(26)
df = pd.read_csv(p)
lines = ["# Cartao Loteca", ""]
for _, r in df.iterrows():
    home = r.get("team_home","")
    away = r.get("team_away","")
    pick = str(r.get("pick","")).upper()
    stake = r.get("stake","")
    lines.append(f"- **{home} x {away}** â€” palpite: {pick}  |  stake: {stake}")
content = "\n".join(lines) + "\n"
with open(f"{out_dir}/loteca_card.md","w",encoding="utf-8") as f:
    f.write(content)
print(f"[loteca] generated: {out_dir}/loteca_card.md")
PYCODE
          test -s "${OUT_DIR}/loteca_card.md" || { echo "::error::loteca_card.md not generated"; exit 26; }
          echo "===== Preview loteca_card.md ====="
          head -n 50 "${OUT_DIR}/loteca_card.md" || true

      # ---------- ARTIFACTS ----------
      - name: Upload artifacts
        if: ${{ always() }}
        uses: actions/upload-artifact@v4
        with:
          name: loteca-${{ steps.prep.outputs.RUN_ID }}
          path: |
            ${{ env.OUT_DIR }}/**
            data/in/matches_source.csv
            data/in/aliases.json
          if-no-files-found: warn