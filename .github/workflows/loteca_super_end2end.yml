name: loteca_super_end2end

on:
  workflow_dispatch:
    inputs:
      season:
        description: "Temporada (ex.: 2025)"
        default: "2025"
        required: true
      lookahead_days:
        description: "Dias para frente (odds)"
        default: "3"
        required: true
      regions:
        description: "Regiões TheOddsAPI"
        default: "uk,eu,us,au"
        required: true
  schedule:
    - cron: "15 9 * * *" # roda diariamente 09:15 UTC (ajuste se quiser)

jobs:
  super-e2e:
    runs-on: ubuntu-latest

    # Variáveis padrão-ouro
    env:
      SEASON: ${{ github.event.inputs.season || '2025' }}
      LOOKAHEAD_DAYS: ${{ github.event.inputs.lookahead_days || '3' }}
      REGIONS: ${{ github.event.inputs.regions || 'uk,eu,us,au' }}
      BANKROLL: "1000"
      KELLY_FRACTION: "0.5"
      KELLY_CAP: "0.1"
      KELLY_TOP_N: "14"
      ROUND_TO: "1"
      TRAIN_CALIBRATOR: "false"
      SOURCE_CSV: data/in/matches_source.csv
      OUT_DIR: data/out/${{ github.run_id }}

      # Mapeamento de secrets (sem usar environment do GH)
      THEODDS_API_KEY: ${{ secrets.THEODDS_API_KEY }}
      API_FOOTBALL_KEY: ${{ secrets.API_FOOTBALL_KEY }}
      X_RAPIDAPI_KEY: ${{ secrets.X_RAPIDAPI_KEY }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies (gold)
        run: |
          set -euo pipefail
          python -m pip install -U pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          # Garantimos as libs necessárias do pipeline
          pip install requests pandas "pyarrow>=14" "fastparquet>=2024.5.0" Unidecode

          # Smoke check
          python - <<'PY'
          import sys, pandas, pyarrow, fastparquet
          import unidecode, requests
          print("[ok] deps prontos")
          PY

      - name: Preparar pastas de trabalho
        run: |
          set -euo pipefail
          mkdir -p "$(dirname "${SOURCE_CSV}")" "${OUT_DIR}" data/history

      # === PRE-FLIGHT: validação do arquivo de jogos (mantido do padrão-ouro) ===
      - name: Validar fonte de jogos (matches_source.csv)
        run: |
          set -euo pipefail
          if [ ! -s "${SOURCE_CSV}" ]; then
            echo "::error::Arquivo ${SOURCE_CSV} não encontrado ou vazio. Crie-o com cabeçalho: match_id,home,away"
            exit 4
          fi
          header="$(head -n1 "${SOURCE_CSV}" | tr -d '\r')"
          for c in match_id home away; do
            echo "$header" | grep -qiE "(^|,)$c(,|$)" || { echo "::error::missing column '$c' em ${SOURCE_CSV}"; exit 4; }
          done

      # === NORMALIZAÇÃO (gera OUT_DIR/matches_norm.csv e copia whitelist) ===
      - name: Normalizar nomes (BR + acentos) e gerar whitelist
        run: |
          set -euo pipefail
          python - <<'PY'
          import csv, os
          from unidecode import unidecode

          src = os.environ["SOURCE_CSV"]
          out_dir = os.environ["OUT_DIR"]
          norm_csv = os.path.join(out_dir, "matches_norm.csv")
          wl_csv = os.path.join(out_dir, "matches_whitelist.csv")

          os.makedirs(out_dir, exist_ok=True)

          # aliases BR mínimos (mantidos e extensíveis)
          aliases = {
            "athletico-pr": "Athletico-PR",
            "atletico-pr": "Athletico-PR",
            "athletico paranaense": "Athletico-PR",
            "atletico paranaense": "Athletico-PR",
            "atletico-go": "Atlético-GO",
            "atletico goianiense": "Atlético-GO",
            "botafogo-sp": "Botafogo-SP",
            "ferroviaria": "Ferroviária",
            "avai": "Avaí",
            "chapecoense": "Chapecoense",
            "volta redonda": "Volta Redonda",
            "crb": "CRB",
            "paysandu": "Paysandu",
            "remo": "Remo",
          }

          def canon(s: str) -> str:
            s0 = (s or "").strip()
            # remove sufixos/uf entre parênteses e barras ex.: "Remo (PA)", "Paysandu/Remo (PA)"
            s1 = s0.replace("/", " ").split("(")[0].strip()
            k = unidecode(s1).lower().replace("  ", " ").replace(" - ", "-")
            k = k.replace("á","a").replace("é","e").replace("í","i").replace("ó","o").replace("ú","u")  # redundante, mas ok
            k = k.replace("ã","a").replace("õ","o").replace("ç","c")
            k = "-".join(part for part in k.replace("  ", " ").split())  # compacta espaços
            return aliases.get(k, s0)  # se tivermos alias, usa; caso contrário, devolve original

          # lê e valida
          with open(src, newline='', encoding='utf-8') as f:
            rd = csv.DictReader(f)
            assert set(["match_id","home","away"]).issubset(rd.fieldnames or []), "Cabeçalho inválido em matches_source.csv"
            rows = list(rd)

          # guarda whitelist 1:1 com a fonte (para modo estrito no consenso)
          with open(wl_csv, "w", newline='', encoding='utf-8') as f:
            wr = csv.DictWriter(f, fieldnames=["match_id","home","away"])
            wr.writeheader()
            for r in rows:
              wr.writerow({"match_id": r["match_id"], "home": r["home"], "away": r["away"]})

          # gera normalizado (mesmos campos, porém ajustados)
          with open(norm_csv, "w", newline='', encoding='utf-8') as f:
            wr = csv.DictWriter(f, fieldnames=["match_id","home","away"])
            wr.writeheader()
            for r in rows:
              wr.writerow({
                "match_id": r["match_id"],
                "home": canon(r["home"]),
                "away": canon(r["away"]),
              })

          print(f"[normalize] OK -> {norm_csv} e whitelist -> {wl_csv}")
          PY

      # === HISTÓRICO: tenta API; se falhar, cria stub BOOT vs BOOT (mantém etapa padrão-ouro) ===
      - name: Atualizar histórico (API) com fallback
        run: |
          set -euo pipefail
          [ -f scripts/update_history.py ] || { echo "::error::scripts/update_history.py not found"; exit 1; }

          if ! python -m scripts.update_history --since_days 14 --out "data/history/results.csv"; then
            echo "::notice::update_history falhou; gerando stub neutro..."
          fi

          if [ ! -s "data/history/results.csv" ] || [ "$(wc -l < data/history/results.csv)" -le 1 ]; then
            printf "date,home,away,home_goals,away_goals\n1970-01-01,BOOT,BOOT,0,0\n" > data/history/results.csv
            echo "::notice::Stub criado (BOOT vs BOOT 0-0) para destravar features."
          fi

          header="$(head -n1 data/history/results.csv | tr -d '\r')"
          for c in date home away home_goals away_goals; do
            echo "$header" | grep -qiE "(^|,)$c(,|$)" || { echo "::error::history sem coluna '$c'"; exit 1; }
          done
          test -s "data/history/results.csv" || { echo "::error::history results.csv not generated"; exit 1; }

      # === FEATURES (parquet) ===
      - name: Feature engineering (EWMA)
        run: |
          set -euo pipefail
          [ -f scripts/feature_engineer.py ] || { echo "::error::scripts/feature_engineer.py not found"; exit 2; }
          python -m scripts.feature_engineer \
            --history "data/history/results.csv" \
            --out "data/history/features.parquet" \
            --ewma 0.20
          test -s "data/history/features.parquet" || { echo "::error::features.parquet not generated"; exit 2; }

      # === THEODDSAPI (OBRIGATÓRIO) ===
      - name: Ingest odds — TheOddsAPI (obrigatório)
        run: |
          set -euo pipefail
          if [ -z "${THEODDS_API_KEY:-}" ]; then
            echo "::error::THEODDS_API_KEY não configurada (Settings > Secrets and variables > Actions)"
            exit 5
          fi
          [ -f scripts/ingest_odds_theoddsapi.py ] || { echo "::error::scripts/ingest_odds_theoddsapi.py not found"; exit 5; }

          python -m scripts.ingest_odds_theoddsapi \
            --rodada "${OUT_DIR}" \
            --regions "${REGIONS}" \
            --source_csv "${OUT_DIR}/matches_norm.csv"

          test -s "${OUT_DIR}/odds_theoddsapi.csv" || { echo "::error::odds_theoddsapi.csv not generated"; exit 5; }

      # === API-FOOTBALL (OPCIONAL — hoje odds não vêm por lá, mas mantemos etapa padrão-ouro) ===
      - name: Ingest odds — API-Football (opcional)
        run: |
          set -euo pipefail
          if [ -z "${API_FOOTBALL_KEY:-}" ]; then
            echo "::notice::API_FOOTBALL_KEY não configurada; pulando ingest_odds_apifootball."
            exit 0
          fi
          if [ ! -f scripts/ingest_odds_apifootball.py ]; then
            echo "::notice::sem scripts/ingest_odds_apifootball.py (ok)"
            exit 0
          fi
          python -m scripts.ingest_odds_apifootball \
            --rodada "${OUT_DIR}" \
            --source_csv "${OUT_DIR}/matches_norm.csv" || true
          [ -s "${OUT_DIR}/odds_apifootball.csv" ] || echo "::notice::odds_apifootball.csv não gerado (ok)"

      # === CONSENSO (STRICT + validação de colunas) ===
      - name: Consensus odds (strict)
        run: |
          set -euo pipefail
          [ -f scripts/consensus_odds_safe.py ] || { echo "::error::scripts/consensus_odds_safe.py not found"; exit 6; }
          python -m scripts.consensus_odds_safe --rodada "${OUT_DIR}" --strict

          OUT_FILE="${OUT_DIR}/odds_consensus.csv"
          test -s "$OUT_FILE" || { echo "::error::odds_consensus.csv not generated"; exit 6; }
          header="$(head -n1 "$OUT_FILE" | tr -d '\r')"
          for c in team_home team_away odds_home odds_draw odds_away; do
            echo "$header" | grep -qiE "(^|,)$c(,|$)" || { echo "::error::missing column '$c' in odds_consensus.csv"; exit 6; }
          done

      # (opcional) — aqui você pode ter seu passo de picks/kelly se existir um script.
      # - name: Picks e staking (Kelly)
      #   run: |
      #     set -euo pipefail
      #     python -m scripts.make_picks --rodada "${OUT_DIR}" --bankroll "${BANKROLL}" \
      #       --kelly_fraction "${KELLY_FRACTION}" --kelly_cap "${KELLY_CAP}" \
      #       --kelly_top_n "${KELLY_TOP_N}" --round_to "${ROUND_TO}"

      - name: Artefatos finais
        run: |
          set -euo pipefail
          echo "OUT_DIR=${OUT_DIR}"
          ls -lah "${OUT_DIR}" || true
          echo "::group::HEADS"
          for f in "${OUT_DIR}/matches_norm.csv" \
                   "${OUT_DIR}/matches_whitelist.csv" \
                   "${OUT_DIR}/odds_theoddsapi.csv" \
                   "${OUT_DIR}/odds_apifootball.csv" \
                   "${OUT_DIR}/odds_consensus.csv"
          do
            if [ -f "$f" ]; then
              echo "--- $f ---"; head -n5 "$f"; echo
            fi
          done
          echo "::endgroup::"

      - name: Upload artefatos
        uses: actions/upload-artifact@v4
        with:
          name: rodada-${{ github.run_id }}
          path: |
            ${{ env.OUT_DIR }}/
            data/history/results.csv
            data/history/features.parquet
          if-no-files-found: warn