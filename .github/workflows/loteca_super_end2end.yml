name: loteca_super_end2end

on:
  workflow_dispatch:
  push:
    branches: [ main, master ]

permissions:
  contents: read

jobs:
  end2end:
    runs-on: ubuntu-latest

    env:
      # ===== Configs gerais =====
      SEASON: 2025
      LOOKAHEAD_DAYS: 3
      REGIONS: uk,eu,us,au

      BANKROLL: 1000
      KELLY_FRACTION: 0.5
      KELLY_CAP: 0.1
      KELLY_TOP_N: 14
      ROUND_TO: 1

      # ligar/desligar calibração (treino + aplicação)
      TRAIN_CALIBRATOR: "false"

      # ===== Entradas =====
      SOURCE_CSV: data/in/matches_source.csv

      # ===== Segredos / APIs =====
      API_FOOTBALL_KEY: ${{ secrets.API_FOOTBALL_KEY }}
      THEODDS_API_KEY: ${{ secrets.THEODDS_API_KEY }}
      X_RAPIDAPI_KEY: ${{ secrets.X_RAPIDAPI_KEY }}

      # ===== Desliga W&B =====
      WANDB_DISABLED: "true"

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies (garante Parquet + Unidecode)
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          else
            pip install pandas numpy scikit-learn requests
          fi
          # Motores de Parquet
          pip install --upgrade "pyarrow>=15.0.0" || true
          pip install --upgrade "fastparquet>=2024.5.0" || true
          # Normalização e fuzzy matching
          pip install --upgrade "Unidecode>=1.3.8" "rapidfuzz>=3.9.0" || true

          python - << 'PY'
          import importlib.util, sys
          def has(mod): return importlib.util.find_spec(mod) is not None
          ok_parquet = has("pyarrow") or has("fastparquet")
          ok_unidecode = has("unidecode")
          missing = []
          if not ok_parquet: missing.append("pyarrow/fastparquet")
          if not ok_unidecode: missing.append("Unidecode")
          if missing:
              sys.exit("Dependências faltando: " + ", ".join(missing))
          PY

      - name: Prepare data folders and stubs
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p data/history data/in data/out data/aliases models
          # stubs seguros (somente se não existirem)
          if [ ! -s "data/history/results.csv" ]; then
            echo "date,home,away,home_goals,away_goals" > data/history/results.csv
            echo "1970-01-01,BOOT,BOOT,0,0" >> data/history/results.csv
          fi
          if [ ! -s "data/in/matches_source.csv" ]; then
            echo "match_id,home,away,date" > data/in/matches_source.csv
            echo "1,BOOT,BOOT,1970-01-01" >> data/in/matches_source.csv
          fi
          if [ ! -s "data/aliases/team_aliases.json" ]; then
            echo "{}" > data/aliases/team_aliases.json
          fi

      - name: Prepare run variables (OUT_DIR etc)
        shell: bash
        run: |
          set -euo pipefail
          OUT_DIR="data/out/${GITHUB_RUN_ID}"
          mkdir -p "${OUT_DIR}"
          echo "OUT_DIR=${OUT_DIR}" >> "$GITHUB_ENV"
          echo "FEATURES_PARQUET=data/history/features.parquet" >> "$GITHUB_ENV"
          echo "SOURCE_CSV_NORM=${OUT_DIR}/matches_norm.csv" >> "$GITHUB_ENV"
          echo "AUTO_ALIASES_JSON=data/aliases/auto_aliases.json" >> "$GITHUB_ENV"
          # artefatos adicionais
          echo "BIVARIATE_CSV=${OUT_DIR}/bivariate.csv" >> "$GITHUB_ENV"
          echo "MODEL_PKL=${OUT_DIR}/dynamic_model.pkl" >> "$GITHUB_ENV"
          echo "STATE_JSON=${OUT_DIR}/state_params.json" >> "$GITHUB_ENV"
          echo "PREDICTIONS_CSV=${OUT_DIR}/predictions.csv" >> "$GITHUB_ENV"
          echo "CALIBRATOR_PKL=${OUT_DIR}/calibrator.pkl" >> "$GITHUB_ENV"
          echo "PREDICTIONS_CALIB_CSV=${OUT_DIR}/predictions_calibrated.csv" >> "$GITHUB_ENV"
          echo "CONSENSUS_CSV=${OUT_DIR}/odds_consensus.csv" >> "$GITHUB_ENV"
          echo "KELLY_BETS_CSV=${OUT_DIR}/bets_kelly.csv" >> "$GITHUB_ENV"
          echo "LOTECA_CARD_CSV=${OUT_DIR}/loteca_card.csv" >> "$GITHUB_ENV"

      - name: Update history (optional)
        shell: bash
        run: |
          set -euo pipefail
          if [ ! -f scripts/update_history.py ]; then
            echo "::notice::scripts/update_history.py not found — usando stub existente"
          else
            python -m scripts.update_history --since_days 14 --out "data/history/results.csv" || echo "::notice::update_history falhou; mantendo stub"
          fi
          [ -s "data/history/results.csv" ] || { echo "::error::results.csv vazio"; exit 1; }

      - name: Feature engineering
        shell: bash
        run: |
          set -euo pipefail
          [ -f scripts/feature_engineer.py ] || { echo "::error::scripts/feature_engineer.py not found"; exit 2; }
          python -m scripts.feature_engineer \
            --history "data/history/results.csv" \
            --out "${FEATURES_PARQUET}" \
            --ewma 0.20
          test -s "${FEATURES_PARQUET}" || { echo "::error::features.parquet not generated"; exit 2; }

      - name: Bivariate analysis (features x alvo) — opcional
        shell: bash
        run: |
          set -euo pipefail
          if [ -f scripts/bivariate_report.py ]; then
            python -m scripts.bivariate_report \
              --features "${FEATURES_PARQUET}" \
              --out "${BIVARIATE_CSV}" || echo "::notice::bivariate falhou; seguindo"
          else
            echo "::notice::scripts/bivariate_report.py não encontrado; pulando"
          fi

      - name: Enrich (API-FOOTBALL) — opcional
        shell: bash
        env:
          API_FOOTBALL_KEY: ${{ env.API_FOOTBALL_KEY }}
        run: |
          set -euo pipefail
          if [ -z "${API_FOOTBALL_KEY:-}" ]; then
            echo "::notice::API_FOOTBALL_KEY não configurada; pulando enrich."
            exit 0
          fi
          if [ ! -f scripts/enrich_api_football.py ]; then
            echo "::notice::sem scripts/enrich_api_football.py"
            exit 0
          fi
          python -m scripts.enrich_api_football \
            --features_in "${FEATURES_PARQUET}" \
            --features_out "${FEATURES_PARQUET}" || true

      - name: Train dynamic model
        shell: bash
        run: |
          set -euo pipefail
          [ -f scripts/train_dynamic_model.py ] || { echo "::error::scripts/train_dynamic_model.py not found"; exit 2; }
          python -m scripts.train_dynamic_model \
            --features "${FEATURES_PARQUET}" \
            --out_state "${STATE_JSON}" \
            --out_model "${MODEL_PKL}"
          test -s "${STATE_JSON}" || { echo "::error::state_params.json not generated"; exit 2; }

      - name: Normalize matches
        shell: bash
        run: |
          set -euo pipefail
          [ -f scripts/normalize_matches.py ] || { echo "::error::scripts/normalize_matches.py not found"; exit 3; }
          python -m scripts.normalize_matches \
            --in_csv "${SOURCE_CSV}" \
            --out_csv "${SOURCE_CSV_NORM}"
          test -s "${SOURCE_CSV_NORM}" || { echo "::error::matches_norm.csv not generated"; exit 3; }

      - name: Harvest aliases automáticos (72h)
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p data/aliases
          if [ ! -f scripts/harvest_aliases.py ]; then
            echo "::notice::sem scripts/harvest_aliases.py — criando auto_aliases.json vazio"
            echo "{}" > "${AUTO_ALIASES_JSON}"
          else
            python -m scripts.harvest_aliases \
              --hours 72 \
              --regions "${REGIONS}" \
              --out "${AUTO_ALIASES_JSON}" || true
            [ -s "${AUTO_ALIASES_JSON}" ] || echo "{}" > "${AUTO_ALIASES_JSON}"
          fi
          echo "::notice::auto_aliases.json pronto em ${AUTO_ALIASES_JSON}"

      - name: Ingest odds — TheOddsAPI (principal)
        shell: bash
        env:
          THEODDS_API_KEY: ${{ env.THEODDS_API_KEY }}
        run: |
          set -euo pipefail
          if [ -z "${THEODDS_API_KEY:-}" ]; then
            echo "::error::THEODDS_API_KEY não configurada"
            exit 5
          fi
          [ -f scripts/ingest_odds_theoddsapi.py ] || { echo "::error::scripts/ingest_odds_theoddsapi.py not found"; exit 5; }
          python -m scripts.ingest_odds_theoddsapi \
            --rodada "${OUT_DIR}" \
            --regions "${REGIONS}" \
            --source_csv "${SOURCE_CSV_NORM}"
          test -s "${OUT_DIR}/odds_theoddsapi.csv" || { echo "::error::odds_theoddsapi.csv not generated"; exit 5; }

      - name: Ingest odds — API-FOOTBALL (complementar/opcional)
        shell: bash
        env:
          API_FOOTBALL_KEY: ${{ env.API_FOOTBALL_KEY }}
        run: |
          set -euo pipefail
          if [ -z "${API_FOOTBALL_KEY:-}" ]; then
            echo "::notice::API_FOOTBALL_KEY não configurada; pulando ingest complementar."
            exit 0
          fi
          if [ ! -f scripts/ingest_odds_apifootball.py ]; then
            echo "::notice::sem scripts/ingest_odds_apifootball.py"
            exit 0
          fi
          python -m scripts.ingest_odds_apifootball \
            --rodada "${OUT_DIR}" \
            --source_csv "${SOURCE_CSV_NORM}" || true

      - name: Consensus odds (safe)
        shell: bash
        run: |
          set -euo pipefail
          [ -f scripts/consensus_odds_safe.py ] || { echo "::error::scripts/consensus_odds_safe.py not found"; exit 6; }
          python -m scripts.consensus_odds_safe --rodada "${OUT_DIR}" --strict
          OUT_FILE="${CONSENSUS_CSV}"
          test -s "${OUT_FILE}" || { echo "::error::odds_consensus.csv not generated"; exit 6; }
          header="$(head -n1 "${OUT_FILE}" | tr -d '\r')"
          for c in team_home team_away odds_home odds_draw odds_away; do
            echo "${header}" | grep -qiE "(^|,)$c(,|$)" || { echo "::error::missing column '$c' in odds_consensus.csv"; exit 6; }
          done

      - name: Predict probabilities (próximos jogos)
        shell: bash
        run: |
          set -euo pipefail
          if [ -f scripts/predict_matches.py ]; then
            python -m scripts.predict_matches \
              --model "${MODEL_PKL}" \
              --state "${STATE_JSON}" \
              --features "${FEATURES_PARQUET}" \
              --matches "${SOURCE_CSV_NORM}" \
              --aliases "${AUTO_ALIASES_JSON}" \
              --out "${PREDICTIONS_CSV}"
            test -s "${PREDICTIONS_CSV}" || echo "::warning::predictions.csv vazio"
          else
            echo "::notice::scripts/predict_matches.py não encontrado; pulando"
          fi

      - name: Train calibrator (opcional)
        if: env.TRAIN_CALIBRATOR == 'true'
        shell: bash
        run: |
          set -euo pipefail
          if [ -f scripts/train_calibrator.py ]; then
            python -m scripts.train_calibrator \
              --history "data/history/results.csv" \
              --features "${FEATURES_PARQUET}" \
              --out "${CALIBRATOR_PKL}" || echo "::notice::train_calibrator falhou"
          else
            echo "::notice::scripts/train_calibrator.py não encontrado; pulando"
          fi

      - name: Apply calibrator (opcional)
        shell: bash
        run: |
          set -euo pipefail
          if [ -f "${CALIBRATOR_PKL}" ] && [ -f "${PREDICTIONS_CSV}" ] && [ -f scripts/apply_calibrator.py ]; then
            python -m scripts.apply_calibrator \
              --in "${PREDICTIONS_CSV}" \
              --calibrator "${CALIBRATOR_PKL}" \
              --out "${PREDICTIONS_CALIB_CSV}" || echo "::notice::apply_calibrator falhou; copiando inalterado"
          fi
          # fallback: se não existir calibrado, usar o bruto
          if [ ! -s "${PREDICTIONS_CALIB_CSV}" ] && [ -f "${PREDICTIONS_CSV}" ]; then
            cp -f "${PREDICTIONS_CSV}" "${PREDICTIONS_CALIB_CSV}" || true
          fi

      - name: Kelly staking & seleção de apostas
        shell: bash
        run: |
          set -euo pipefail
          if [ -f scripts/kelly_bets.py ] && [ -s "${PREDICTIONS_CALIB_CSV}" ] && [ -s "${CONSENSUS_CSV}" ]; then
            python -m scripts.kelly_bets \
              --pred "${PREDICTIONS_CALIB_CSV}" \
              --odds "${CONSENSUS_CSV}" \
              --bankroll "${BANKROLL}" \
              --kelly_frac "${KELLY_FRACTION}" \
              --kelly_cap "${KELLY_CAP}" \
              --top_n "${KELLY_TOP_N}" \
              --round_to "${ROUND_TO}" \
              --out "${KELLY_BETS_CSV}"
            test -s "${KELLY_BETS_CSV}" || echo "::warning::bets_kelly.csv vazio"
          else
            echo "::notice::kelly_bets prerequisites ausentes; pulando"
          fi

      - name: Cartão da Loteca (1X2)
        shell: bash
        run: |
          set -euo pipefail
          if [ -f scripts/render_loteca_card.py ] && [ -s "${PREDICTIONS_CALIB_CSV}" ]; then
            python -m scripts.render_loteca_card \
              --pred "${PREDICTIONS_CALIB_CSV}" \
              --out_csv "${LOTECA_CARD_CSV}" \
              --season "${SEASON}" \
              --rodada_dir "${OUT_DIR}" || echo "::notice::render_loteca_card falhou"
          else
            echo "::notice::render_loteca_card prerequisites ausentes; pulando"
          fi

      - name: Diagnostic sweep (não falha o job)
        shell: bash
        run: |
          set -euo pipefail
          if [ -f scripts/diag_pipeline.py ]; then
            python -m scripts.diag_pipeline || true
          else
            echo "::warning::scripts/diag_pipeline.py não encontrado; pulando diagnóstico"
          fi

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: loteca-out-${{ github.run_id }}
          path: |
            ${{ env.OUT_DIR }}/**
            data/aliases/auto_aliases.json
            data/aliases/auto_aliases_suggestions.json
            data/history/results.csv
            data/history/features.parquet
          if-no-files-found: warn