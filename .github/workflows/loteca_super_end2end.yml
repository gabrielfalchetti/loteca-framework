name: Loteca Super End-to-End

on:
  workflow_dispatch:
    inputs:
      season:
        description: "Temporada (ex: 2025)"
        required: true
        default: "2025"
      lookahead_days:
        description: "Dias à frente para odds (ex: 3)"
        required: true
        default: "3"
      bankroll:
        description: "Bankroll para Kelly"
        required: true
        default: "1000"
      kelly_fraction:
        description: "Kelly fraction (0..1)"
        required: true
        default: "0.5"
      kelly_cap:
        description: "Limite máximo por aposta (0..1)"
        required: true
        default: "0.1"
      kelly_top_n:
        description: "Qtd máxima de apostas"
        required: true
        default: "14"
      round_to:
        description: "Arredondamento do stake"
        required: true
        default: "1"
      regions:
        description: "Regiões TheOddsAPI (ex: uk,eu,us,au)"
        required: true
        default: "uk,eu,us,au"
      train_calibrator:
        description: "Treinar calibrador isotônico nesta execução? (true/false)"
        required: true
        default: "false"

jobs:
  loteca-e2e:
    runs-on: ubuntu-latest
    # Se usar Environment Secrets, descomente a linha abaixo e ajuste o nome:
    # environment: prod

    env:
      SEASON: ${{ github.event.inputs.season }}
      LOOKAHEAD_DAYS: ${{ github.event.inputs.lookahead_days }}
      REGIONS: ${{ github.event.inputs.regions }}
      BANKROLL: ${{ github.event.inputs.bankroll }}
      KELLY_FRACTION: ${{ github.event.inputs.kelly_fraction }}
      KELLY_CAP: ${{ github.event.inputs.kelly_cap }}
      KELLY_TOP_N: ${{ github.event.inputs.kelly_top_n }}
      ROUND_TO: ${{ github.event.inputs.round_to }}
      TRAIN_CALIBRATOR: ${{ github.event.inputs.train_calibrator }}

      PYTHONUTF8: 1
      PIP_DISABLE_PIP_VERSION_CHECK: 1
      PIP_NO_WARN_SCRIPT_LOCATION: 1

      # Secrets injetados no job (não usar expressões em "if:" para secrets)
      API_FOOTBALL_KEY: ${{ secrets.API_FOOTBALL_KEY }}
      THEODDS_API_KEY: ${{ secrets.THEODDS_API_KEY }}
      X_RAPIDAPI_KEY:  ${{ secrets.X_RAPIDAPI_KEY }}

      # Caminho da whitelist de jogos (arquivo de entrada do usuário)
      SOURCE_CSV: data/in/matches_source.csv

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install pandas numpy scipy scikit-learn requests unidecode pyarrow fastparquet

      - name: (debug) Verificar chaves carregadas
        shell: bash
        run: |
          set -euo pipefail
          for v in API_FOOTBALL_KEY THEODDS_API_KEY X_RAPIDAPI_KEY; do
            if [ -z "${!v:-}" ]; then
              echo "::notice::$v está VAZIO (ok se você não usar esta fonte agora)"
            else
              echo "::notice::$v está definido"
            fi
          done

      - name: Prepare RUN_ID and OUT_DIR
        shell: bash
        run: |
          set -euo pipefail
          RUN_ID="$(date +%s)"
          OUT_DIR="data/out/${RUN_ID}"
          echo "RUN_ID=${RUN_ID}" >> "$GITHUB_ENV"
          echo "OUT_DIR=${OUT_DIR}" >> "$GITHUB_ENV"
          mkdir -p "data/in" "${OUT_DIR}" "data/history"
          echo "RUN_ID=${RUN_ID}"
          echo "OUT_DIR=${OUT_DIR}"

      - name: Validar matches_source.csv e copiar whitelist
        shell: bash
        env:
          OUT_DIR: ${{ env.OUT_DIR }}
          SOURCE_CSV: ${{ env.SOURCE_CSV }}
        run: |
          set -euo pipefail
          if [ ! -s "${SOURCE_CSV}" ]; then
            echo "::error::Arquivo ${SOURCE_CSV} não encontrado ou vazio. Crie-o com cabeçalho: match_id,home,away"
            exit 4
          fi
          header="$(head -n1 "${SOURCE_CSV}" | tr -d '\r')"
          for c in match_id home away; do
            echo "$header" | grep -qiE "(^|,)$c(,|$)" || { echo "::error::missing column '$c' em ${SOURCE_CSV}"; exit 4; }
          done
          cp -f "${SOURCE_CSV}" "${OUT_DIR}/matches_whitelist.csv"
          echo "::notice::Whitelist copiada para ${OUT_DIR}/matches_whitelist.csv"

      # 1) UPDATE HISTORICAL DATA (robusto; garante colunas home_goals/away_goals)
      - name: Update Historical Data
        shell: bash
        run: |
          set -euo pipefail
          [ -f scripts/update_history.py ] || { echo "::error::scripts/update_history.py not found"; exit 1; }
          # tenta buscar; se falhar, criará stub dentro do próprio script
          python -m scripts.update_history --since_days 14 --out "data/history/results.csv"
          # sanity check
          header="$(head -n1 data/history/results.csv | tr -d '\r')"
          for c in date home away home_goals away_goals; do
            echo "$header" | grep -qiE "(^|,)$c(,|$)" || { echo "::error::history sem coluna '$c'"; exit 1; }
          done
          test -s "data/history/results.csv" || { echo "::error::history results.csv not generated"; exit 1; }

      # 2) FEATURE ENGINEERING (com fallback de parquet)
        # mantém sua lógica; usa parquet se disponível (pyarrow/fastparquet), senão CSV
      - name: Build Features
        shell: bash
        run: |
          set -euo pipefail
          [ -f scripts/feature_engineer.py ] || { echo "::error::scripts/feature_engineer.py not found"; exit 2; }
          python -m scripts.feature_engineer \
            --history "data/history/results.csv" \
            --out "data/history/features.parquet" \
            --ewma 0.20
          test -s "data/history/features.parquet" || { echo "::error::features.parquet not generated"; exit 2; }

      # 3) (opcional) modelos seus — deixei como estavam
      - name: Train Dynamic Poisson Model
        shell: bash
        env:
          OUT_DIR: ${{ env.OUT_DIR }}
        run: |
          set -euo pipefail
          [ -f scripts/train_dynamic_model.py ] || { echo "::error::scripts/train_dynamic_model.py not found"; exit 7; }
          python -m scripts.train_dynamic_model \
            --rodada "${OUT_DIR}" \
            --history "data/history/results.csv" \
            --features "data/history/features.parquet" \
            --ewma 0.20
          test -s "${OUT_DIR}/state_params.json" || { echo "::error::state_params.json not generated"; exit 7; }

      # 4) INGEST FUTURE MATCHES & ODDS — sem aliases, usando normalização PT↔EN e whitelist
      - name: Ingest API-Football (opcional)
        shell: bash
        env:
          OUT_DIR: ${{ env.OUT_DIR }}
          SOURCE_CSV: ${{ env.SOURCE_CSV }}
        run: |
          set -euo pipefail
          if [ -z "${API_FOOTBALL_KEY:-}" ]; then
            echo "::notice::API_FOOTBALL_KEY não configurada; pulando ingest_odds_apifootball."
            exit 0
          fi
          [ -f scripts/ingest_odds_apifootball.py ] || { echo "::error::scripts/ingest_odds_apifootball.py not found"; exit 5; }
          a=0
          until [ $a -ge 3 ]; do
            python -m scripts.ingest_odds_apifootball \
              --rodada "${OUT_DIR}" \
              --source_csv "${SOURCE_CSV}" && break
            a=$((a+1)); echo "retry apifootball: $a/3"; sleep $((5*a))
          done
          [ -s "${OUT_DIR}/odds_apifootball.csv" ] || echo "::warning::odds_apifootball.csv not generated"

      - name: Ingest TheOddsAPI (recomendado)
        shell: bash
        env:
          OUT_DIR: ${{ env.OUT_DIR }}
          SOURCE_CSV: ${{ env.SOURCE_CSV }}
          REGIONS: ${{ env.REGIONS }}
        run: |
          set -euo pipefail
          if [ -z "${THEODDS_API_KEY:-}" ]; then
            echo "::notice::THEODDS_API_KEY não configurada; pulando ingest_odds_theoddsapi."
            exit 0
          fi
          [ -f scripts/ingest_odds_theoddsapi.py ] || { echo "::error::scripts/ingest_odds_theoddsapi.py not found"; exit 5; }
          a=0
          until [ $a -ge 3 ]; do
            python -m scripts.ingest_odds_theoddsapi \
              --rodada "${OUT_DIR}" \
              --regions "${REGIONS}" \
              --source_csv "${SOURCE_CSV}" && break
            a=$((a+1)); echo "retry theodds: $a/3"; sleep $((5*a))
          done
          [ -s "${OUT_DIR}/odds_theoddsapi.csv" ] || echo "::warning::odds_theoddsapi.csv not generated"

      # 5) CONSENSUS (strict exige odds para todos os jogos da whitelist)
      - name: Consensus Odds (strict)
        shell: bash
        env:
          OUT_DIR: ${{ env.OUT_DIR }}
        run: |
          set -euo pipefail
          [ -f scripts/consensus_odds_safe.py ] || { echo "::error::scripts/consensus_odds_safe.py not found"; exit 6; }
          python -m scripts.consensus_odds_safe --rodada "${OUT_DIR}" --strict
          OUT_FILE="${OUT_DIR}/odds_consensus.csv"
          test -s "$OUT_FILE" || { echo "::error::odds_consensus.csv not generated"; exit 6; }
          header="$(head -n1 "$OUT_FILE" | tr -d '\r')"
          for c in team_home team_away odds_home odds_draw odds_away; do
            echo "$header" | grep -qiE "(^|,)$c(,|$)" || { echo "::error::missing column '$c' in odds_consensus.csv"; exit 6; }
          done

      # 6) (opcional) TREINAR CALIBRADOR
      - name: Train Calibrator (optional)
        if: ${{ env.TRAIN_CALIBRATOR == 'true' }}
        shell: bash
        run: |
          set -euo pipefail
          [ -f scripts/train_calibrator.py ] || { echo "::error::scripts/train_calibrator.py not found"; exit 12; }
          python -m scripts.train_calibrator \
            --history "data/history/results.csv" \
            --pred_store "data/history/predictions.csv" \
            --out_dir "data/history/calibration"
          test -s "data/history/calibration/calibrator_home.pkl" || { echo "::error::calibrator files not generated"; exit 12; }

      # 7) PREVISÃO ÚNICA
      - name: Predict (Dynamic Bivariate Poisson)
        shell: bash
        env:
          OUT_DIR: ${{ env.OUT_DIR }}
        run: |
          set -euo pipefail
          [ -f scripts/xg_bivariate.py ] || { echo "::error::scripts/xg_bivariate.py not found"; exit 8; }
          python -m scripts.xg_bivariate --rodada "${OUT_DIR}" --max_goals 10
          OUT="${OUT_DIR}/xg_bivariate.csv"
          test -s "$OUT" || { echo "::error::xg_bivariate.csv not generated"; exit 8; }

      # 8) CALIBRAÇÃO (aplica calibrador treinado)
      - name: Calibrate probabilities
        shell: bash
        env:
          OUT_DIR: ${{ env.OUT_DIR }}
        run: |
          set -euo pipefail
          [ -f scripts/calibrate_probs.py ] || { echo "::error::scripts/calibrate_probs.py not found"; exit 9; }
          python -m scripts.calibrate_probs --rodada "${OUT_DIR}"
          OUT="${OUT_DIR}/probs_calibrated.csv"
          test -s "$OUT" || { echo "::error::probs_calibrated.csv not generated"; exit 9; }

      # 9) KELLY
      - name: Kelly bets
        shell: bash
        env:
          OUT_DIR: ${{ env.OUT_DIR }}
          BANKROLL: ${{ env.BANKROLL }}
          KELLY_FRACTION: ${{ env.KELLY_FRACTION }}
          KELLY_CAP: ${{ env.KELLY_CAP }}
          KELLY_TOP_N: ${{ env.KELLY_TOP_N }}
          ROUND_TO: ${{ env.ROUND_TO }}
        run: |
          set -euo pipefail
          [ -f scripts/kelly_bets.py ] || { echo "::error::scripts/kelly_bets.py not found"; exit 10; }
          python -m scripts.kelly_bets \
            --rodada "${OUT_DIR}" \
            --bankroll "${BANKROLL}" \
            --fraction "${KELLY_FRACTION}" \
            --cap "${KELLY_CAP}" \
            --topn "${KELLY_TOP_N}" \
            --round_to "${ROUND_TO}"
          OUT="${OUT_DIR}/kelly_stakes.csv"
          test -s "$OUT" || { echo "::error::kelly_stakes.csv not generated"; exit 10; }

      # 10) TICKET LOTECA
      - name: Build Loteca ticket
        shell: bash
        env:
          OUT_DIR: ${{ env.OUT_DIR }}
        run: |
          set -euo pipefail
          [ -f scripts/make_loteca_ticket.py ] || { echo "::error::scripts/make_loteca_ticket.py not found"; exit 11; }
          python -m scripts.make_loteca_ticket --rodada "${OUT_DIR}"
          OUT="${OUT_DIR}/loteca_ticket.csv"
          test -s "$OUT" || { echo "::error::loteca_ticket.csv not generated"; exit 11; }

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: rodada-${{ env.RUN_ID }}
          path: |
            ${{ env.OUT_DIR }}/*.csv
            ${{ env.OUT_DIR }}/*.json
            data/history/*.csv
            data/history/*.parquet
            data/history/calibration/*.pkl