name: Loteca Super End2End

on:
  workflow_dispatch:
  schedule:
    - cron: "15 12 * * *"

jobs:
  super:
    runs-on: ubuntu-latest

    env:
      SEASON: "2025"
      LOOKAHEAD_DAYS: "3"
      REGIONS: "uk,eu,us,au"
      BANKROLL: "1000"
      KELLY_FRACTION: "0.5"
      KELLY_CAP: "0.10"
      KELLY_TOP_N: "14"
      ROUND_TO: "1"
      TRAIN_CALIBRATOR: "false"
      SOURCE_CSV: "data/in/matches_source.csv"
      THEODDS_API_KEY: ${{ secrets.THEODDS_API_KEY }}
      API_FOOTBALL_KEY: ${{ secrets.API_FOOTBALL_KEY }}
      X_RAPIDAPI_KEY: ${{ secrets.X_RAPIDAPI_KEY }}
      WANDB_DISABLED: "true"

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt || true
          fi
          pip install --upgrade pandas numpy requests python-dateutil unidecode rapidfuzz pyarrow scikit-learn

      - name: Prepare data folders and stubs
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p data/history data/in data/out data/aliases models
          if [ ! -s "data/history/results.csv" ]; then
            echo "date,home,away,home_goals,away_goals" > data/history/results.csv
            echo "1970-01-01,BOOT,BOOT,0,0" >> data/history/results.csv
          fi
          if [ ! -s "data/in/matches_source.csv" ]; then
            echo "match_id,home,away,date" > data/in/matches_source.csv
            echo "1,BOOT,BOOT,1970-01-01 00:00:00+00:00" >> data/in/matches_source.csv
          fi
          if [ ! -s "data/aliases/team_aliases.json" ]; then
            echo "{}" > data/aliases/team_aliases.json
          fi

      - name: Define run variables
        shell: bash
        run: |
          set -euo pipefail
          OUT_DIR="data/out/${GITHUB_RUN_ID}"
          mkdir -p "${OUT_DIR}"
          {
            echo "OUT_DIR=${OUT_DIR}"
            echo "FEATURES_PARQUET=data/history/features.parquet"
            echo "SOURCE_CSV_NORM=${OUT_DIR}/matches_norm.csv"
            echo "AUTO_ALIASES_JSON=data/aliases/auto_aliases.json"
            echo "BIVARIATE_CSV=${OUT_DIR}/bivariate.csv"
            echo "MODEL_PKL=${OUT_DIR}/dynamic_model.pkl"
            echo "STATE_JSON=${OUT_DIR}/state_params.json"
            echo "PREDICTIONS_CSV=${OUT_DIR}/predictions.csv"
            echo "CALIBRATOR_PKL=${OUT_DIR}/calibrator.pkl"
            echo "PREDICTIONS_CALIB_CSV=${OUT_DIR}/predictions_calibrated.csv"
            echo "CONSENSUS_CSV=${OUT_DIR}/odds_consensus.csv"
            echo "KELLY_BETS_CSV=${OUT_DIR}/bets_kelly.csv"
            echo "LOTECA_CARD_CSV=${OUT_DIR}/loteca_card.csv"
          } >> "$GITHUB_ENV"

      # ============ History / Features / Enrich / Train ============
      - name: Update history (optional)
        shell: bash
        run: |
          set -euo pipefail
          if [ -f scripts/update_history.py ]; then
            python -m scripts.update_history --since_days 14 --out "data/history/results.csv" || \
              echo "::notice::update_history falhou; mantendo stub"
          else
            echo "::notice::scripts/update_history.py nao encontrado; mantendo stub"
          fi
          [ -s "data/history/results.csv" ] || { echo "::error::results.csv vazio"; exit 1; }

      - name: Feature engineering
        shell: bash
        run: |
          set -euo pipefail
          [ -f scripts/feature_engineer.py ] || { echo "::error::scripts/feature_engineer.py not found"; exit 2; }
          python -m scripts.feature_engineer \
            --history "data/history/results.csv" \
            --out "${FEATURES_PARQUET}" \
            --ewma 0.20
          test -s "${FEATURES_PARQUET}" || { echo "::error::features.parquet not generated"; exit 2; }

      - name: Enrich features with API-Football (optional)
        shell: bash
        run: |
          set -euo pipefail
          if [ -z "${API_FOOTBALL_KEY:-}" ]; then
            echo "::notice::API_FOOTBALL_KEY nao configurada; pulando enrich."
            exit 0
          fi
          if [ ! -f scripts/enrich_api_football.py ]; then
            echo "::notice::sem scripts/enrich_api_football.py"
            exit 0
          fi
          python -m scripts.enrich_api_football \
            --features_in "${FEATURES_PARQUET}" \
            --features_out "${FEATURES_PARQUET}" || true
          echo "[enrich] pass-through/OK"

      - name: Train dynamic model
        shell: bash
        run: |
          set -euo pipefail
          [ -f scripts/train_dynamic_model.py ] || { echo "::error::scripts/train_dynamic_model.py not found"; exit 2; }
          python -m scripts.train_dynamic_model \
            --features "${FEATURES_PARQUET}" \
            --out_state "${STATE_JSON}" \
            --out_model "${MODEL_PKL}"
          test -s "${STATE_JSON}" || { echo "::error::state_params.json not generated"; exit 2; }
          test -s "${MODEL_PKL}" || { echo "::error::dynamic_model.pkl not generated"; exit 2; }

      # ========================= Matches source =========================
      - name: Normalize matches
        shell: bash
        run: |
          set -euo pipefail
          [ -f scripts/normalize_matches.py ] || { echo "::error::scripts/normalize_matches.py not found"; exit 3; }
          python -m scripts.normalize_matches \
            --in_csv  "${SOURCE_CSV}" \
            --out_csv "${SOURCE_CSV_NORM}"
          test -s "${SOURCE_CSV_NORM}" || { echo "::error::matches_norm.csv not generated"; exit 3; }

      - name: Auto-alias harvester (optional)
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p data/aliases
          if [ -f scripts/harvest_aliases.py ]; then
            python -m scripts.harvest_aliases \
              --source_csv "${SOURCE_CSV_NORM}" \
              --lookahead_hours 72 \
              --out_json "${AUTO_ALIASES_JSON}" || \
            python -m scripts.harvest_aliases \
              --hours 72 --regions "${REGIONS}" --out "${AUTO_ALIASES_JSON}" || true
            [ -s "${AUTO_ALIASES_JSON}" ] || echo "{}" > "${AUTO_ALIASES_JSON}"
          else
            echo "::notice::sem scripts/harvest_aliases.py; criando auto_aliases.json vazio"
            echo "{}" > "${AUTO_ALIASES_JSON}"
          fi
          echo "::notice::auto_aliases.json pronto em ${AUTO_ALIASES_JSON}"

      # ======= TheOddsAPI: Preflight + Ingest + Fallback =======
      - name: Preflight TheOddsAPI Serie A
        shell: bash
        run: |
          set -euo pipefail
          cat > /tmp/preflight_theodds.py <<'PY'
import os, json, urllib.request, urllib.parse
api = os.environ.get("THEODDS_API_KEY")
regions = os.environ.get("REGIONS","eu")
if not api:
    print("[preflight] THEODDS_API_KEY ausente; pulando.")
    raise SystemExit(0)
qs = urllib.parse.urlencode({"regions":regions,"markets":"h2h","dateFormat":"iso","oddsFormat":"decimal","apiKey":api})
url = f"https://api.the-odds-api.com/v4/sports/soccer_brazil_campeonato/odds?{qs}"
try:
    with urllib.request.urlopen(url, timeout=25) as r:
        data = json.load(r)
    if isinstance(data, dict) and data.get("message"):
        print("[preflight] API message:", data["message"])
    else:
        print(f"[preflight] eventos Serie A (h2h) = {len(data)}")
        for e in (data or [])[:5]:
            print(" -", e.get("home_team"), "vs", e.get("away_team"), "@", e.get("commence_time"))
except Exception as e:
    print("[preflight] erro:", e)
PY
          python /tmp/preflight_theodds.py

      - name: Ingest TheOddsAPI primary
        shell: bash
        run: |
          set -euo pipefail
          if [ -z "${THEODDS_API_KEY:-}" ]; then
            echo "::error::THEODDS_API_KEY nao configurada"
            exit 5
          fi
          [ -f scripts/ingest_odds_theoddsapi.py ] || { echo "::error::scripts/ingest_odds_theoddsapi.py not found"; exit 5; }
          python -m scripts.ingest_odds_theoddsapi \
            --rodada "${OUT_DIR}" \
            --regions "${REGIONS}" \
            --source_csv "${SOURCE_CSV_NORM}"

      - name: Fallback TheOddsAPI direct fetch if empty
        shell: bash
        run: |
          set -euo pipefail
          if [ -z "${THEODDS_API_KEY:-}" ]; then
            echo "::notice::THEODDS_API_KEY nao configurada; pulando fallback."
            exit 0
          fi
          OUT="${OUT_DIR}/odds_theoddsapi.csv"
          if [ -s "$OUT" ] && [ "$(wc -l < "$OUT")" -gt 1 ]; then
            echo "[fallback] odds_theoddsapi.csv parece valido; pulando."
            exit 0
          fi
          echo "[fallback] coleta direta TheOddsAPIâ€¦"
          cat > /tmp/fallback_theodds.py <<'PY'
import os, csv, json, sys, urllib.request, urllib.parse
API=os.environ.get("THEODDS_API_KEY")
REG=os.environ.get("REGIONS","eu")
OUT=os.path.join(os.environ["OUT_DIR"], "odds_theoddsapi.csv")
def fetch(sport):
    qs = urllib.parse.urlencode(dict(apiKey=API, regions=REG, markets="h2h", oddsFormat="decimal", dateFormat="iso"))
    url=f"https://api.the-odds-api.com/v4/sports/{sport}/odds?{qs}"
    with urllib.request.urlopen(url, timeout=25) as r:
        return json.load(r)
rows=[]
for sport in ("soccer_brazil_campeonato","soccer_brazil_serie_b"):
    try:
        data = fetch(sport) or []
        for ev in data:
            home = ev.get("home_team") or ""
            away = ev.get("away_team") or ""
            best = {"home":None,"draw":None,"away":None}
            for b in ev.get("bookmakers",[]):
                for mk in b.get("markets",[]):
                    if mk.get("key")!="h2h": continue
                    for o in mk.get("outcomes",[]) or []:
                        n=o.get("name",""); p=o.get("price",None)
                        if p is None: continue
                        if n==home:
                            best["home"]=max(best["home"] or 0,p)
                        elif n==away:
                            best["away"]=max(best["away"] or 0,p)
                        elif n.lower()=="draw":
                            best["draw"]=max(best["draw"] or 0,p)
            if all(best[k] for k in ("home","draw","away")):
                rows.append([home,away,best["home"],best["draw"],best["away"]])
    except Exception as e:
        print(f"[fallback] erro no esporte {sport}: {e}", file=sys.stderr)
os.makedirs(os.path.dirname(OUT), exist_ok=True)
with open(OUT,"w",newline="",encoding="utf-8") as f:
    w=csv.writer(f)
    w.writerow(["team_home","team_away","odds_home","odds_draw","odds_away"])
    for r in rows: w.writerow(r)
print(f"[fallback] escrito {OUT} com {len(rows)} linhas")
PY
          python /tmp/fallback_theodds.py
          if [ ! -s "$OUT" ] || [ "$(wc -l < "$OUT")" -le 1 ]; then
            echo "::warning::Fallback nao obteve odds; pipeline seguira sem odds da TheOddsAPI."
          fi

      - name: Ingest API-Football odds optional
        shell: bash
        run: |
          set -euo pipefail
          if [ -z "${API_FOOTBALL_KEY:-}" ]; then
            echo "::notice::API_FOOTBALL_KEY nao configurada; pulando ingest complementar."
            exit 0
          fi
          if [ ! -f scripts/ingest_odds_apifootball.py ]; then
            echo "::notice::sem scripts/ingest_odds_apifootball.py"
            exit 0
          fi
          python -m scripts.ingest_odds_apifootball \
            --rodada "${OUT_DIR}" \
            --source_csv "${SOURCE_CSV_NORM}" || true
          echo "[apifootball] ingest complementar finalizado"

      - name: Consensus odds with fallback
        shell: bash
        run: |
          set -euo pipefail
          OUT_FILE="${CONSENSUS_CSV}"
          if [ -f scripts/consensus_odds_safe.py ]; then
            python -m scripts.consensus_odds_safe --rodada "${OUT_DIR}" --strict || true
          fi
          if [ ! -s "${OUT_FILE}" ]; then
            if [ -s "${OUT_DIR}/odds_theoddsapi.csv" ]; then
              cp "${OUT_DIR}/odds_theoddsapi.csv" "${OUT_FILE}"
              echo "::notice::consensus caiu no fallback (somente TheOddsAPI)."
            else
              echo "::error::consensus nao gerado e nao ha odds_theoddsapi.csv"
              exit 6
            fi
          fi
          header="$(head -n1 "${OUT_FILE}" | tr -d '\r')"
          for c in team_home team_away odds_home odds_draw odds_away; do
            echo "${header}" | grep -qiE "(^|,)$c(,|$)" || { echo "::error::missing column '$c' in odds_consensus.csv"; exit 6; }
          done
          echo "[consensus] OK - ${OUT_FILE}"

      # ============ Bivariate / Predictions / Calibration ============
      - name: Bivariate or fallback 1-3-3
        shell: bash
        run: |
          set -euo pipefail
          if [ -f scripts/bivariate_estimator.py ]; then
            python -m scripts.bivariate_estimator \
              --history "${FEATURES_PARQUET}" \
              --matches "${SOURCE_CSV_NORM}" \
              --out "${BIVARIATE_CSV}" || true
          fi
          if [ ! -s "${BIVARIATE_CSV}" ]; then
            cat > /tmp/bivariate_fallback.py <<'PY'
import csv, os
src=os.environ["SOURCE_CSV_NORM"]; out=os.environ["BIVARIATE_CSV"]
rows=[]
with open(src, newline="", encoding="utf-8") as f:
    r=csv.DictReader(f)
    for row in r:
        rows.append([row["home"], row["away"], 1/3, 1/3, 1/3])
os.makedirs(os.path.dirname(out), exist_ok=True)
with open(out,"w",newline="",encoding="utf-8") as f:
    w=csv.writer(f); w.writerow(["team_home","team_away","p_home","p_draw","p_away"]); w.writerows(rows)
print(f"[bivariate] fallback gerado {out} com {len(rows)} jogos")
PY
            python /tmp/bivariate_fallback.py
          fi
          test -s "${BIVARIATE_CSV}" || { echo "::error::bivariate.csv not generated"; exit 7; }

      - name: Predict dynamic or bivariate
        shell: bash
        run: |
          set -euo pipefail
          if [ -f scripts/predict_dynamic_model.py ]; then
            python -m scripts.predict_dynamic_model \
              --model "${MODEL_PKL}" \
              --state "${STATE_JSON}" \
              --matches "${SOURCE_CSV_NORM}" \
              --out "${PREDICTIONS_CSV}" || true
          fi
          if [ ! -s "${PREDICTIONS_CSV}" ]; then
            cat > /tmp/predict_from_bivariate.py <<'PY'
import csv, os
biv=os.environ["BIVARIATE_CSV"]; out=os.environ["PREDICTIONS_CSV"]
rows=[]
with open(biv, newline="", encoding="utf-8") as f:
    r=csv.DictReader(f)
    for row in r:
        rows.append([row["team_home"],row["team_away"],row["p_home"],row["p_draw"],row["p_away"]])
with open(out,"w",newline="",encoding="utf-8") as f:
    w=csv.writer(f); w.writerow(["team_home","team_away","p_home","p_draw","p_away"]); w.writerows(rows)
print(f"[predict] fallback (bivariate) -> {out} ({len(rows)} jogos)")
PY
            python /tmp/predict_from_bivariate.py
          fi
          test -s "${PREDICTIONS_CSV}" || { echo "::error::predictions.csv not generated"; exit 8; }

      - name: Train calibrator or identity
        shell: bash
        run: |
          set -euo pipefail
          if [ "${TRAIN_CALIBRATOR}" = "true" ] && [ -f scripts/calibrator_train.py ]; then
            python -m scripts.calibrator_train \
              --history "${FEATURES_PARQUET}" \
              --out "${CALIBRATOR_PKL}" || true
          fi
          if [ ! -s "${CALIBRATOR_PKL}" ]; then
            cat > /tmp/calibrator_identity.py <<'PY'
import pickle, os
out=os.environ["CALIBRATOR_PKL"]
cal={"type":"identity"}
with open(out,"wb") as f: pickle.dump(cal,f)
print("[calibrator] identity criado", out)
PY
            python /tmp/calibrator_identity.py
          fi

      - name: Apply calibration
        shell: bash
        run: |
          set -euo pipefail
          cat > /tmp/apply_calibration.py <<'PY'
import csv, pickle, os
pred=os.environ["PREDICTIONS_CSV"]
out=os.environ["PREDICTIONS_CALIB_CSV"]
with open(os.environ["CALIBRATOR_PKL"],"rb") as f:
    cal=pickle.load(f)
rows=[]
with open(pred, newline="", encoding="utf-8") as f:
    r=csv.DictReader(f)
    for row in r:
        ph, pd, pa = float(row["p_home"]), float(row["p_draw"]), float(row["p_away"])
        s = ph+pd+pa
        if s>0: ph,pd,pa = ph/s, pd/s, pa/s
        rows.append([row["team_home"],row["team_away"],ph,pd,pa])
with open(out,"w",newline="",encoding="utf-8") as f:
    w=csv.writer(f); w.writerow(["team_home","team_away","p_home","p_draw","p_away"]); w.writerows(rows)
print(f"[calibration] escrito {out} ({len(rows)} jogos)")
PY
          python /tmp/apply_calibration.py
          test -s "${PREDICTIONS_CALIB_CSV}" || { echo "::error::predictions_calibrated.csv not generated"; exit 9; }

      # ============ Kelly / Loteca card ============
      - name: Kelly staking 1x2
        shell: bash
        run: |
          set -euo pipefail
          cat > /tmp/kelly.py <<'PY'
import csv, os
BANK=float(os.environ.get("BANKROLL","1000"))
FRAC=float(os.environ.get("KELLY_FRACTION","0.5"))
CAP=float(os.environ.get("KELLY_CAP","0.10"))
ROUND_TO=int(os.environ.get("ROUND_TO","1"))
pred=os.environ["PREDICTIONS_CALIB_CSV"]
odds=os.environ["CONSENSUS_CSV"]
out=os.environ["KELLY_BETS_CSV"]
odict={}
with open(odds, newline="", encoding="utf-8") as f:
    r=csv.DictReader(f)
    for row in r:
        key=(row["team_home"],row["team_away"])
        odict[key]=(float(row["odds_home"]), float(row["odds_draw"]), float(row["odds_away"]))
rows=[]
def kelly(p,o,frac,cap):
    b=o-1.0
    k=(p*b-(1-p))/b if b>0 else 0.0
    k=max(0.0, min(k*frac, cap))
    return k
with open(pred, newline="", encoding="utf-8") as f:
    r=csv.DictReader(f)
    for row in r:
        key=(row["team_home"],row["team_away"])
        if key not in odict: continue
        ph,pd,pa = float(row["p_home"]), float(row["p_draw"]), float(row["p_away"])
        oh,od,oa = odict[key]
        kh,kd,ka = kelly(ph,oh,FRAC,CAP), kelly(pd,od,FRAC,CAP), kelly(pa,oa,FRAC,CAP)
        side,k,o,p = max([("H",kh,oh,ph),("D",kd,od,pd),("A",ka,oa,pa)], key=lambda x: x[1])
        stake = round(BANK * k, ROUND_TO)
        ev = p*o - 1
        rows.append([row["team_home"], row["team_away"], side, p, o, k, stake, ev])
with open(out,"w",newline="",encoding="utf-8") as f:
    w=csv.writer(f)
    w.writerow(["team_home","team_away","side","p","odds","kelly_frac","stake","expected_value"])
    w.writerows(rows)
print(f"[kelly] bets -> {out} ({len(rows)} jogos)")
PY
          python /tmp/kelly.py
          test -s "${KELLY_BETS_CSV}" || { echo "::error::bets_kelly.csv not generated"; exit 10; }

      - name: Loteca card top N
        shell: bash
        run: |
          set -euo pipefail
          cat > /tmp/loteca_card.py <<'PY'
import csv, os
TOP=int(os.environ.get("KELLY_TOP_N","14"))
bets=os.environ["KELLY_BETS_CSV"]
out=os.environ["LOTECA_CARD_CSV"]
rows=[]
with open(bets, newline="", encoding="utf-8") as f:
    r=csv.DictReader(f); rows=list(r)
rows.sort(key=lambda x:(float(x["stake"]), float(x["expected_value"])), reverse=True)
rows=rows[:TOP]
with open(out,"w",newline="",encoding="utf-8") as f:
    w=csv.writer(f)
    w.writerow(["jogo","home","away","palpite","stake","odds","p","ev"])
    for i,row in enumerate(rows,1):
        palpite={"H":"1","D":"X","A":"2"}[row["side"]]
        w.writerow([i, row["team_home"], row["team_away"], palpite,
                    row["stake"], row["odds"], row["p"], row["expected_value"]])
print(f"[loteca] card -> {out} ({len(rows)} jogos)")
PY
          python /tmp/loteca_card.py
          test -s "${LOTECA_CARD_CSV}" || { echo "::error::loteca_card.csv not generated"; exit 11; }

      # ============ Diagnostics and list ============
      - name: Diagnostics optional
        shell: bash
        run: |
          set -euo pipefail
          if [ -f scripts/diag_pipeline.py ]; then
            HAS_ODDS=0
            [ -s "${CONSENSUS_CSV}" ] && HAS_ODDS=1
            export HAS_ODDS
            python -m scripts.diag_pipeline || true
          else
            echo "::warning::scripts/diag_pipeline.py nao encontrado; pulando diagnostico"
          fi

      - name: List outputs
        shell: bash
        run: |
          set -euo pipefail
          ls -lh "${OUT_DIR}" || true
          echo "OUT_DIR=${OUT_DIR}"