
name: loteca_super_end2end

on:
  workflow_dispatch:
    inputs:
      season:
        description: "Temporada (ex.: 2025)"
        default: "2025"
        required: true
      lookahead_days:
        description: "Dias para frente (odds)"
        default: "3"
        required: true
      regions:
        description: "Regiões TheOddsAPI"
        default: "uk,eu,us,au"
        required: true
  schedule:
    - cron: "15 9 * * *" # diário 09:15 UTC

jobs:
  super-e2e:
    runs-on: ubuntu-latest

    env:
      SEASON: ${{ github.event.inputs.season || '2025' }}
      LOOKAHEAD_DAYS: ${{ github.event.inputs.lookahead_days || '3' }}
      REGIONS: ${{ github.event.inputs.regions || 'uk,eu,us,au' }}

      BANKROLL: "1000"
      KELLY_FRACTION: "0.5"
      KELLY_CAP: "0.1"
      KELLY_TOP_N: "14"
      ROUND_TO: "1"
      TRAIN_CALIBRATOR: "false"

      SOURCE_CSV: data/in/matches_source.csv
      OUT_DIR: data/out/${{ github.run_id }}

      THEODDS_API_KEY: ${{ secrets.THEODDS_API_KEY }}
      API_FOOTBALL_KEY: ${{ secrets.API_FOOTBALL_KEY }}
      X_RAPIDAPI_KEY: ${{ secrets.X_RAPIDAPI_KEY }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies (gold)
        run: |
          set -euo pipefail
          python -m pip install -U pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

          # Núcleo do pipeline + modelagem + parquet + normalização
          pip install \
            requests pandas numpy scipy scikit-learn statsmodels joblib \
            "pyarrow>=14" "fastparquet>=2024.5.0" Unidecode

          python - <<'PY'
          import pandas, pyarrow, fastparquet, numpy, scipy, sklearn, statsmodels.api as sm  # smoke
          import unidecode, requests
          print("[ok] deps prontos")
          PY

      - name: Preparar pastas
        run: |
          set -euo pipefail
          mkdir -p "$(dirname "${SOURCE_CSV}")" "${OUT_DIR}" data/history

      # -------------------- PRE-FLIGHT: jogos --------------------
      - name: Validar fonte de jogos (matches_source.csv)
        run: |
          set -euo pipefail
          if [ ! -s "${SOURCE_CSV}" ]; then
            echo "::error::Arquivo ${SOURCE_CSV} não encontrado ou vazio. Crie-o com cabeçalho: match_id,home,away"
            exit 4
          fi
          header="$(head -n1 "${SOURCE_CSV}" | tr -d '\r')"
          for c in match_id home away; do
            echo "$header" | grep -qiE "(^|,)$c(,|$)" || { echo "::error::missing column '$c' em ${SOURCE_CSV}"; exit 4; }
          done

      - name: Normalizar nomes (BR + acentos) e gerar whitelist
        run: |
          set -euo pipefail
          python - <<'PY'
          import csv, os, re
          from unidecode import unidecode

          src = os.environ["SOURCE_CSV"]
          out_dir = os.environ["OUT_DIR"]
          norm_csv = os.path.join(out_dir, "matches_norm.csv")
          wl_csv = os.path.join(out_dir, "matches_whitelist.csv")
          os.makedirs(out_dir, exist_ok=True)

          aliases = {
            "athletico-pr": "Athletico-PR",
            "atletico-pr": "Athletico-PR",
            "athletico paranaense": "Athletico-PR",
            "atletico paranaense": "Athletico-PR",
            "atletico-go": "Atlético-GO",
            "atletico goianiense": "Atlético-GO",
            "botafogo-sp": "Botafogo-SP",
            "ferroviaria": "Ferroviária",
            "avai": "Avaí",
            "chapecoense": "Chapecoense",
            "volta redonda": "Volta Redonda",
            "crb": "CRB",
            "paysandu": "Paysandu",
            "remo": "Remo",
          }

          def canon(s: str) -> str:
            s0 = (s or "").strip()
            s1 = s0.replace("/", " ").split("(")[0].strip()
            k = unidecode(s1).lower()
            k = re.sub(r"\s+", " ", k).strip().replace(" - ", "-")
            k = k.replace("ç","c")
            k = "-".join(k.split())
            return aliases.get(k, s0)

          with open(src, newline='', encoding='utf-8') as f:
            rd = csv.DictReader(f)
            assert set(["match_id","home","away"]).issubset(rd.fieldnames or []), "Cabeçalho inválido"
            rows = list(rd)

          with open(wl_csv, "w", newline='', encoding='utf-8') as f:
            wr = csv.DictWriter(f, fieldnames=["match_id","home","away"])
            wr.writeheader()
            wr.writerows(rows)

          with open(norm_csv, "w", newline='', encoding='utf-8') as f:
            wr = csv.DictWriter(f, fieldnames=["match_id","home","away"])
            wr.writeheader()
            for r in rows:
              wr.writerow({"match_id": r["match_id"], "home": canon(r["home"]), "away": canon(r["away"])})
          print(f"[normalize] OK -> {norm_csv} & {wl_csv}")
          PY

      # -------------------- HISTÓRICO & FEATURES --------------------
      - name: Atualizar histórico (API) com fallback
        run: |
          set -euo pipefail
          [ -f scripts/update_history.py ] || { echo "::error::scripts/update_history.py not found"; exit 1; }

          if ! python -m scripts.update_history --since_days 14 --out "data/history/results.csv"; then
            echo "::notice::update_history falhou; gerando stub neutro..."
          fi

          if [ ! -s "data/history/results.csv" ] || [ "$(wc -l < data/history/results.csv)" -le 1 ]; then
            printf "date,home,away,home_goals,away_goals\n1970-01-01,BOOT,BOOT,0,0\n" > data/history/results.csv
            echo "::notice::Stub criado (BOOT vs BOOT 0-0) para destravar features."
          fi

          header="$(head -n1 data/history/results.csv | tr -d '\r')"
          for c in date home away home_goals away_goals; do
            echo "$header" | grep -qiE "(^|,)$c(,|$)" || { echo "::error::history sem coluna '$c'"; exit 1; }
          done

      - name: Feature engineering (EWMA)
        run: |
          set -euo pipefail
          [ -f scripts/feature_engineer.py ] || { echo "::error::scripts/feature_engineer.py not found"; exit 2; }
          python -m scripts.feature_engineer \
            --history "data/history/results.csv" \
            --out "data/history/features.parquet" \
            --ewma 0.20
          test -s "data/history/features.parquet" || { echo "::error::features.parquet not generated"; exit 2; }

      # -------------------- ODDS --------------------
      - name: Ingest odds — TheOddsAPI (obrigatório)
        run: |
          set -euo pipefail
          if [ -z "${THEODDS_API_KEY:-}" ]; then
            echo "::error::THEODDS_API_KEY não configurada (Settings > Secrets and variables > Actions)"
            exit 5
          fi
          [ -f scripts/ingest_odds_theoddsapi.py ] || { echo "::error::scripts/ingest_odds_theoddsapi.py not found"; exit 5; }

          python -m scripts.ingest_odds_theoddsapi \
            --rodada "${OUT_DIR}" \
            --regions "${REGIONS}" \
            --source_csv "${OUT_DIR}/matches_norm.csv"

          test -s "${OUT_DIR}/odds_theoddsapi.csv" || { echo "::error::odds_theoddsapi.csv not generated"; exit 5; }

      - name: Ingest odds — API-Football (opcional)
        run: |
          set -euo pipefail
          if [ -z "${API_FOOTBALL_KEY:-}" ]; then
            echo "::notice::API_FOOTBALL_KEY não configurada; pulando ingest_odds_apifootball."
            exit 0
          fi
          if [ ! -f scripts/ingest_odds_apifootball.py ]; then
            echo "::notice::sem scripts/ingest_odds_apifootball.py (ok)"
            exit 0
          fi
          python -m scripts.ingest_odds_apifootball \
            --rodada "${OUT_DIR}" \
            --source_csv "${OUT_DIR}/matches_norm.csv" || true
          [ -s "${OUT_DIR}/odds_apifootball.csv" ] || echo "::notice::odds_apifootball.csv não gerado (ok)"

      - name: Consensus odds (strict)
        run: |
          set -euo pipefail
          [ -f scripts/consensus_odds_safe.py ] || { echo "::error::scripts/consensus_odds_safe.py not found"; exit 6; }
          python -m scripts.consensus_odds_safe --rodada "${OUT_DIR}" --strict

          OUT_FILE="${OUT_DIR}/odds_consensus.csv"
          test -s "$OUT_FILE" || { echo "::error::odds_consensus.csv not generated"; exit 6; }
          header="$(head -n1 "$OUT_FILE" | tr -d '\r')"
          for c in team_home team_away odds_home odds_draw odds_away; do
            echo "$header" | grep -qiE "(^|,)$c(,|$)" || { echo "::error::missing column '$c' in odds_consensus.csv"; exit 6; }
          done

      # -------------------- xG BIVARIADO --------------------
      - name: xG bivariado — prever probabilidades (p_home/draw/away)
        run: |
          set -euo pipefail
          # Descobre automaticamente o script de modelo
          XG_SCRIPT=""
          for cand in \
            scripts/xg_bivariate.py \
            scripts/model_xg_bivariate.py \
            scripts/model_bivariate_xg.py \
            scripts/xg_poisson_bivariate.py
          do
            if [ -f "$cand" ]; then XG_SCRIPT="$cand"; break; fi
          done
          if [ -z "$XG_SCRIPT" ]; then
            echo "::error::script de xG bivariado não encontrado (procurei por xg_bivariate.py / model_xg_bivariate.py / model_bivariate_xg.py / xg_poisson_bivariate.py)"
            exit 7
          fi
          MOD="${XG_SCRIPT%.py}"; MOD="${MOD//\//.}"

          CAL=""
          if [ "${TRAIN_CALIBRATOR}" = "true" ]; then CAL="--train-calibrator"; fi

          python -m "$MOD" \
            --features "data/history/features.parquet" \
            --odds "${OUT_DIR}/odds_consensus.csv" \
            --out   "${OUT_DIR}/predictions.csv" \
            $CAL

          PRED="${OUT_DIR}/predictions.csv"
          test -s "$PRED" || { echo "::error::predictions.csv não gerado"; exit 7; }
          header="$(head -n1 "$PRED" | tr -d '\r')"
          for c in match_id team_home team_away p_home p_draw p_away; do
            echo "$header" | grep -qiE "(^|,)$c(,|$)" || { echo "::error::missing column '$c' em predictions.csv"; exit 7; }
          done

      # -------------------- KELLY STAKING --------------------
      - name: Picks e staking (Kelly)
        run: |
          set -euo pipefail
          # Descobre automaticamente o script de picks
          KELLY_SCRIPT=""
          for cand in \
            scripts/make_picks.py \
            scripts/picks_kelly.py \
            scripts/kelly.py
          do
            if [ -f "$cand" ]; then KELLY_SCRIPT="$cand"; break; fi
          done
          if [ -z "$KELLY_SCRIPT" ]; then
            echo "::error::script de Kelly não encontrado (procurei por make_picks.py / picks_kelly.py / kelly.py)"
            exit 8
          fi
          MOD="${KELLY_SCRIPT%.py}"; MOD="${MOD//\//.}"

          python -m "$MOD" \
            --rodada "${OUT_DIR}" \
            --odds   "${OUT_DIR}/odds_consensus.csv" \
            --preds  "${OUT_DIR}/predictions.csv" \
            --bankroll "${BANKROLL}" \
            --kelly_fraction "${KELLY_FRACTION}" \
            --kelly_cap "${KELLY_CAP}" \
            --top_n "${KELLY_TOP_N}" \
            --round_to "${ROUND_TO}"

          PICKS="${OUT_DIR}/picks_kelly.csv"
          test -s "$PICKS" || { echo "::error::picks_kelly.csv não gerado"; exit 8; }
          head -n1 "$PICKS" | grep -qiE "(^|,)stake(,|$)" || echo "::warning::coluna 'stake' não detectada em picks_kelly.csv (ok se seu script usa outro nome)"

      # -------------------- ARTEFATOS --------------------
      - name: Artefatos finais
        run: |
          set -euo pipefail
          echo "OUT_DIR=${OUT_DIR}"
          ls -lah "${OUT_DIR}" || true
          echo "::group::HEADS"
          for f in "${OUT_DIR}/matches_norm.csv" \
                   "${OUT_DIR}/matches_whitelist.csv" \
                   "${OUT_DIR}/odds_theoddsapi.csv" \
                   "${OUT_DIR}/odds_apifootball.csv" \
                   "${OUT_DIR}/odds_consensus.csv" \
                   "${OUT_DIR}/predictions.csv" \
                   "${OUT_DIR}/picks_kelly.csv"
          do
            if [ -f "$f" ]; then
              echo "--- $f ---"; head -n5 "$f"; echo
            fi
          done
          echo "::endgroup::"

      - name: Upload artefatos
        uses: actions/upload-artifact@v4
        with:
          name: rodada-${{ github.run_id }}
          path: |
            ${{ env.OUT_DIR }}/
            data/history/results.csv
            data/history/features.parquet
          if-no-files-found: warn